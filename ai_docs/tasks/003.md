# Task 003: Database Setup with PostgreSQL and pgvector

## Overview
Set up PostgreSQL database with pgvector extension for vector similarity search, create initial schema, implement connection pooling, and establish database migration framework using Alembic.

## Success Criteria
- [ ] PostgreSQL 15+ with pgvector extension is operational
- [ ] Database connection pooling is implemented and tested
- [ ] Alembic migrations can be run successfully
- [ ] Vector similarity search performs queries in <100ms for 10k vectors
- [ ] Database health checks pass consistently
- [ ] Connection pool handles 100+ concurrent connections

## Test First Approach

### Tests to Write BEFORE Implementation:

1. **Database Connection Tests** (`tests/backend/unit/test_database.py`):
```python
def test_database_connection():
    """Test database connectivity and basic operations."""
    # Test connection can be established
    # Test connection pool is created with correct size
    # Test connections are properly released
    # Test connection timeout handling

def test_pgvector_extension():
    """Test pgvector extension is properly installed."""
    # Test vector extension is available
    # Test vector operations work
    # Test vector dimension validation
    # Test vector similarity functions

def test_connection_pool_limits():
    """Test connection pool behaves correctly under load."""
    # Test max connections are enforced
    # Test connection wait timeout
    # Test pool overflow handling
    # Test connection recycling
```

2. **Migration Tests** (`tests/backend/unit/test_migrations.py`):
```python
def test_migration_up_down():
    """Test migrations can be applied and rolled back."""
    # Test all migrations run successfully
    # Test migrations are reversible
    # Test migration history is tracked
    # Test schema matches expected state

def test_migration_idempotency():
    """Test migrations can be run multiple times safely."""
    # Test running migrations twice doesn't error
    # Test partial migration recovery
    # Test migration dependency resolution
```

3. **Vector Operation Tests** (`tests/backend/unit/test_vector_operations.py`):
```python
def test_vector_insert_retrieve():
    """Test vector storage and retrieval."""
    # Test inserting vectors of various dimensions
    # Test retrieving vectors by ID
    # Test batch vector operations
    # Test vector metadata storage

def test_vector_similarity_search():
    """Test vector similarity search performance."""
    # Test cosine similarity search
    # Test L2 distance search
    # Test search with filters
    # Test search performance benchmarks

def test_vector_indexing():
    """Test vector indexing strategies."""
    # Test index creation
    # Test index performance improvement
    # Test index maintenance
    # Test concurrent index usage
```

## Implementation Details

1. **Database Schema** (`alembic/versions/001_initial_schema.py`):
```sql
-- Core tables
CREATE TABLE IF NOT EXISTS projects (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(255) NOT NULL,
    description TEXT,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE IF NOT EXISTS documents (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    project_id UUID REFERENCES projects(id) ON DELETE CASCADE,
    file_path VARCHAR(1024) NOT NULL,
    content TEXT,
    file_type VARCHAR(50),
    size_bytes INTEGER,
    hash VARCHAR(64),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(project_id, file_path)
);

CREATE TABLE IF NOT EXISTS embeddings (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    document_id UUID REFERENCES documents(id) ON DELETE CASCADE,
    chunk_index INTEGER NOT NULL,
    chunk_text TEXT NOT NULL,
    embedding vector(1536),  -- OpenAI embedding dimension
    metadata JSONB,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(document_id, chunk_index)
);

-- Indexes for performance
CREATE INDEX idx_embeddings_vector ON embeddings 
    USING ivfflat (embedding vector_cosine_ops)
    WITH (lists = 100);

CREATE INDEX idx_documents_project ON documents(project_id);
CREATE INDEX idx_embeddings_document ON embeddings(document_id);
```

2. **Database Configuration** (`app/db/base.py`):
   - SQLAlchemy 2.0 with async support
   - Connection pooling with configurable size
   - Automatic reconnection on failure
   - Query logging in development
   - Connection health checks

3. **Vector Operations Module** (`app/db/vector_ops.py`):
   - Async vector insertion with batching
   - Similarity search with multiple algorithms
   - Filtered vector search
   - Vector aggregation operations
   - Performance monitoring

4. **Migration Setup**:
   - Alembic configuration for schema versioning
   - Auto-generation of migrations from models
   - Migration testing framework
   - Rollback procedures
   - Data migration utilities

5. **Connection Pool Management**:
   - Min/max pool size configuration
   - Connection timeout settings
   - Connection recycling after errors
   - Pool statistics monitoring
   - Graceful shutdown handling

## Dependencies
- Task 001: Development Environment Setup
- Task 002: Project Structure and Configuration

## Estimated Time
16-20 hours

## Required Skills
- PostgreSQL administration
- pgvector extension knowledge
- SQLAlchemy ORM (async)
- Database connection pooling
- Alembic migrations
- Vector database concepts
- SQL performance optimization