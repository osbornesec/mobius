# Task 007: File Ingestion System

## Overview
Build a robust file ingestion system that can process Python, JavaScript, TypeScript, and Markdown files, extract content, parse code structure, and prepare data for embedding generation.

## Success Criteria
- [ ] System ingests 1000+ files per hour
- [ ] Supports Python, JavaScript, TypeScript, and Markdown
- [ ] Extracts code structure (classes, functions, imports)
- [ ] Handles file encoding and binary detection
- [ ] Processes large files (>1MB) efficiently
- [ ] Maintains file metadata and relationships

## Test First Approach

### Tests to Write BEFORE Implementation:

1. **File Detection Tests** (`backend/tests/test_file_detection.py`):
```python
def test_file_type_detection():
    """Test accurate file type detection."""
    # Test Python file detection (.py, .pyi)
    # Test JavaScript detection (.js, .jsx)
    # Test TypeScript detection (.ts, .tsx)
    # Test Markdown detection (.md, .mdx)
    # Test binary file rejection

def test_encoding_detection():
    """Test file encoding detection."""
    # Test UTF-8 detection
    # Test other encodings (UTF-16, ASCII)
    # Test encoding errors handling
    # Test BOM handling
```

2. **Parser Tests** (`backend/tests/test_parsers.py`):
```python
def test_python_parser():
    """Test Python code parsing."""
    # Test class extraction
    # Test function extraction
    # Test import extraction
    # Test docstring extraction
    # Test syntax error handling

def test_javascript_parser():
    """Test JavaScript/TypeScript parsing."""
    # Test function extraction
    # Test class extraction
    # Test import/export extraction
    # Test JSDoc extraction
    # Test syntax error handling

def test_markdown_parser():
    """Test Markdown parsing."""
    # Test header extraction
    # Test code block extraction
    # Test link extraction
    # Test frontmatter parsing
    # Test table of contents generation
```

3. **Ingestion Pipeline Tests** (`backend/tests/test_ingestion_pipeline.py`):
```python
def test_single_file_ingestion():
    """Test single file processing."""
    # Test file reading
    # Test content extraction
    # Test metadata generation
    # Test database storage
    # Test error handling

def test_batch_ingestion():
    """Test batch file processing."""
    # Test concurrent processing
    # Test progress tracking
    # Test partial failure handling
    # Test memory efficiency
    # Test rate limiting

def test_large_file_handling():
    """Test large file processing."""
    # Test streaming for large files
    # Test chunking strategy
    # Test memory usage limits
    # Test timeout handling
```

## Implementation Details

1. **File Detection Module** (`backend/app/ingestion/detectors.py`):
```python
class FileDetector:
    SUPPORTED_EXTENSIONS = {
        '.py': 'python',
        '.pyi': 'python',
        '.js': 'javascript',
        '.jsx': 'javascript',
        '.ts': 'typescript',
        '.tsx': 'typescript',
        '.md': 'markdown',
        '.mdx': 'markdown'
    }
    
    def detect_file_type(self, file_path: Path) -> Optional[str]:
        # Extension-based detection
        # Content-based detection fallback
        # Binary file detection
        # Encoding detection
```

2. **Language Parsers** (`backend/app/ingestion/parsers/`):
   - **Python Parser**: Use `ast` module for syntax tree parsing
   - **JavaScript/TypeScript Parser**: Use `@babel/parser` via subprocess
   - **Markdown Parser**: Use `markdown-it` with plugins
   - Common interface for all parsers
   - Error recovery mechanisms

3. **Code Structure Extraction**:
```python
class CodeStructure:
    file_path: str
    language: str
    classes: List[ClassInfo]
    functions: List[FunctionInfo]
    imports: List[ImportInfo]
    exports: List[ExportInfo]
    comments: List[CommentInfo]
    
class ClassInfo:
    name: str
    line_start: int
    line_end: int
    methods: List[str]
    docstring: Optional[str]
    decorators: List[str]
    
class FunctionInfo:
    name: str
    line_start: int
    line_end: int
    parameters: List[str]
    docstring: Optional[str]
    decorators: List[str]
    is_async: bool
```

4. **Ingestion Pipeline** (`backend/app/ingestion/pipeline.py`):
   - File discovery and filtering
   - Parallel processing with worker pool
   - Progress tracking and reporting
   - Duplicate detection (file hash)
   - Incremental updates support
   - Transaction management

5. **Chunking Strategy** (`backend/app/ingestion/chunking.py`):
   - Semantic chunking (respect code boundaries)
   - Size-based chunking with overlap
   - Maintain context in chunks
   - Chunk metadata (position, parent)
   - Cross-reference preservation

6. **Metadata Extraction**:
   - File size and timestamps
   - Git information (if available)
   - Code metrics (complexity, lines)
   - Dependencies detected
   - Documentation coverage
   - Test file associations

## Dependencies
- Task 002: Project Structure
- Task 003: Database Setup
- Task 005: FastAPI Core

## Estimated Time
16-20 hours

## Required Skills
- File I/O and encoding
- Language parsing (AST)
- Regular expressions
- Concurrent programming
- Memory optimization
- Git integration
- Code analysis