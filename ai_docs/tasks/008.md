# Task 008: Vector Embedding Generation

## Overview
Implement vector embedding generation using OpenAI's Embeddings API, including batching, rate limiting, cost optimization, and fallback strategies for high availability.

## Success Criteria
- [ ] Generate embeddings for 10k+ text chunks efficiently
- [ ] Implement proper rate limiting to avoid API throttling
- [ ] Batch API calls for cost optimization
- [ ] Handle API failures with exponential backoff
- [ ] Cache embeddings to avoid regeneration
- [ ] Track embedding costs and usage metrics

## Test First Approach

### Tests to Write BEFORE Implementation:

1. **Embedding Client Tests** (`tests/backend/unit/test_embedding_client.py`):
```python
def test_openai_client_initialization():
    """Test OpenAI client setup and configuration."""
    # Test API key configuration
    # Test client initialization
    # Test model selection
    # Test timeout settings
    # Test retry configuration

def test_embedding_generation():
    """Test single embedding generation."""
    # Test successful embedding generation
    # Test embedding dimension (1536)
    # Test empty text handling
    # Test max token limit handling
    # Test special character handling

def test_api_error_handling():
    """Test API error scenarios."""
    # Test rate limit errors (429)
    # Test server errors (500)
    # Test invalid API key
    # Test network timeouts
    # Test invalid input errors
```

2. **Batching Tests** (`tests/backend/unit/test_embedding_batch.py`):
```python
def test_batch_processing():
    """Test batch embedding generation."""
    # Test optimal batch sizing
    # Test batch queue management
    # Test partial batch handling
    # Test batch timeout behavior
    # Test memory efficiency

def test_batch_failure_recovery():
    """Test batch failure scenarios."""
    # Test partial batch failures
    # Test retry individual items
    # Test batch splitting on failure
    # Test progress persistence
```

3. **Cost Optimization Tests** (`tests/backend/unit/test_cost_optimization.py`):
```python
def test_embedding_cache():
    """Test embedding cache effectiveness."""
    # Test cache hit for duplicate text
    # Test cache invalidation
    # Test cache size limits
    # Test cache persistence
    # Test cache key generation

def test_token_counting():
    """Test accurate token counting."""
    # Test token estimation accuracy
    # Test cost calculation
    # Test usage tracking
    # Test budget limits enforcement
```

## Implementation Details

1. **Embedding Service** (`app/embeddings/service.py`):
```python
class EmbeddingService:
    def __init__(
        self,
        api_key: str,
        model: str = "text-embedding-3-small",
        max_retries: int = 3,
        batch_size: int = 100
    ):
        self.client = OpenAI(api_key=api_key)
        self.model = model
        self.batch_queue = asyncio.Queue()
        self.cost_tracker = CostTracker()

    async def generate_embedding(
        self,
        text: str,
        cache_key: Optional[str] = None
    ) -> List[float]:
        # Check cache first
        # Validate input length
        # Generate embedding
        # Cache result
        # Track costs
```

2. **Batch Processing** (`app/embeddings/batch.py`):
   - Automatic batching with configurable size
   - Time-based batch triggers
   - Priority queue for urgent requests
   - Progress tracking and resumption
   - Failed item reprocessing

3. **Rate Limiting** (`app/embeddings/rate_limiter.py`):
```python
class EmbeddingRateLimiter:
    # Token bucket algorithm
    # Adaptive rate adjustment
    # Multi-tenant fairness
    # Burst capacity handling
    # Metrics collection

    async def acquire(self, tokens: int):
        # Wait if necessary
        # Track wait times
        # Priority handling
```

4. **Cost Management** (`app/embeddings/cost_tracker.py`):
   - Real-time cost tracking
   - Budget alerts and limits
   - Cost per project/user tracking
   - Historical cost analysis
   - Optimization recommendations

5. **Caching Strategy** (`app/embeddings/cache.py`):
   - Content-based cache keys
   - Multi-level caching (Redis + DB)
   - Cache warming for common texts
   - Invalidation on model changes
   - Compression for storage efficiency

6. **Fallback Strategies**:
   - Local embedding models (Sentence Transformers)
   - Alternative API providers
   - Degraded mode operation
   - Queue persistence during outages
   - Automatic recovery

## Dependencies
- Task 004: Redis Cache Layer
- Task 007: File Ingestion System

## Estimated Time
14-18 hours

## Required Skills
- OpenAI API integration
- Async programming
- Rate limiting algorithms
- Batch processing patterns
- Cost optimization
- Caching strategies
- Error handling
