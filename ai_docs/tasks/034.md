# Task 034: Specialized Domain Agents Implementation

## Overview
Implement specialized domain agents for security analysis, performance optimization, testing assistance, and documentation generation. These agents will provide expert-level assistance in their respective domains within the Mobius platform.

## Success Criteria
- [ ] Security Agent identifies vulnerabilities with >90% accuracy
- [ ] Performance Agent provides actionable optimization recommendations
- [ ] Testing Agent generates comprehensive test suites with >80% coverage
- [ ] Documentation Agent creates accurate and helpful documentation
- [ ] All agents integrate seamlessly with the multi-agent framework
- [ ] Agents demonstrate domain expertise comparable to human specialists

## Test First Approach

### Tests to Write BEFORE Implementation:

1. **Security Agent Tests** (`tests/backend/unit/test_security_agent.py`):
```python
def test_vulnerability_detection():
    """Test security vulnerability detection accuracy."""
    # Test SQL injection detection
    # Test XSS vulnerability identification
    # Test authentication bypass detection
    # Test cryptographic weakness identification
    # Test access control vulnerability detection

def test_security_recommendations():
    """Test security recommendation generation."""
    # Test remediation step generation
    # Test security best practice suggestions
    # Test compliance requirement mapping
    # Test risk severity assessment
    # Test security pattern recognition

def test_security_compliance_checks():
    """Test compliance framework validation."""
    # Test OWASP Top 10 compliance
    # Test SOC 2 requirement validation
    # Test GDPR compliance checks
    # Test industry-specific requirements
    # Test security audit trail generation
```

2. **Performance Agent Tests** (`tests/backend/unit/test_performance_agent.py`):
```python
def test_performance_analysis():
    """Test performance bottleneck identification."""
    # Test algorithmic complexity analysis
    # Test memory usage optimization
    # Test database query optimization
    # Test caching opportunity identification
    # Test async/await pattern analysis

def test_optimization_recommendations():
    """Test performance optimization suggestions."""
    # Test code refactoring recommendations
    # Test infrastructure optimization
    # Test caching strategy suggestions
    # Test database index recommendations
    # Test load balancing suggestions

def test_performance_metrics():
    """Test performance measurement accuracy."""
    # Test execution time analysis
    # Test memory consumption analysis
    # Test throughput optimization
    # Test latency reduction suggestions
    # Test scalability assessment
```

3. **Testing Agent Tests** (`tests/backend/unit/test_testing_agent.py`):
```python
def test_test_generation():
    """Test automated test case generation."""
    # Test unit test generation
    # Test integration test generation
    # Test edge case identification
    # Test mock object creation
    # Test assertion generation

def test_coverage_analysis():
    """Test code coverage analysis."""
    # Test coverage gap identification
    # Test critical path analysis
    # Test boundary condition testing
    # Test error condition testing
    # Test performance test generation

def test_test_quality():
    """Test generated test quality metrics."""
    # Test assertion accuracy
    # Test test maintainability
    # Test test readability
    # Test test execution efficiency
    # Test false positive/negative rates
```

4. **Documentation Agent Tests** (`tests/backend/unit/test_documentation_agent.py`):
```python
def test_documentation_generation():
    """Test automated documentation generation."""
    # Test API documentation generation
    # Test code comment generation
    # Test README file creation
    # Test architecture documentation
    # Test user guide generation

def test_documentation_quality():
    """Test documentation quality metrics."""
    # Test accuracy of generated content
    # Test completeness of documentation
    # Test readability and clarity
    # Test consistency with code
    # Test user-friendliness
```

## Implementation Details

1. **Security Agent** (`app/agents/security_agent.py`):
```python
from typing import Dict, Any, List, Optional
from dataclasses import dataclass
from enum import Enum
import re
import ast
from datetime import datetime

from app.agents.base_agent import BaseAgent, AgentCapability
from app.models.domain.security import SecurityVulnerability, SecurityReport, RiskLevel

class VulnerabilityType(Enum):
    SQL_INJECTION = "sql_injection"
    XSS = "xss"
    CSRF = "csrf"
    AUTHENTICATION_BYPASS = "auth_bypass"
    AUTHORIZATION_FLAW = "authz_flaw"
    CRYPTO_WEAKNESS = "crypto_weakness"
    INSECURE_DESERIALIZATION = "insecure_deserialization"
    SECURITY_MISCONFIGURATION = "security_misconfiguration"
    KNOWN_VULNERABILITIES = "known_vulnerabilities"
    INSUFFICIENT_LOGGING = "insufficient_logging"

@dataclass
class SecurityAnalysisRequest:
    file_paths: List[str]
    analysis_type: str  # "full", "quick", "targeted"
    compliance_frameworks: List[str] = None
    exclude_patterns: List[str] = None
    include_dependencies: bool = True

@dataclass
class SecurityAnalysisResult:
    vulnerabilities: List[SecurityVulnerability]
    security_score: float
    compliance_status: Dict[str, bool]
    recommendations: List[str]
    risk_assessment: Dict[str, Any]
    analysis_metadata: Dict[str, Any]

class SecurityAgent(BaseAgent):
    def __init__(self):
        capabilities = [
            AgentCapability("vulnerability_scanning", "1.0", 10, {"supports_owasp": True}),
            AgentCapability("security_analysis", "1.0", 9, {"supports_compliance": True}),
            AgentCapability("risk_assessment", "1.0", 8, {"supports_scoring": True}),
            AgentCapability("remediation_guidance", "1.0", 9, {"supports_automation": True})
        ]
        super().__init__("security_agent", "security", capabilities)
        
        self.vulnerability_patterns = self._load_vulnerability_patterns()
        self.compliance_rules = self._load_compliance_rules()
        self.security_knowledge_base = {}
        
    async def on_start(self):
        """Initialize the security agent."""
        # Load security knowledge base
        await self._load_security_knowledge_base()
        
        # Initialize vulnerability scanners
        await self._initialize_scanners()
        
        # Load compliance frameworks
        await self._load_compliance_frameworks()
        
    async def handle_message(self, message) -> Optional[Any]:
        """Handle security analysis requests."""
        action = message.payload.get("action")
        
        if action == "analyze_security":
            request = SecurityAnalysisRequest(**message.payload.get("request", {}))
            result = await self.analyze_security(request)
            return result.__dict__
        elif action == "check_vulnerability":
            return await self.check_specific_vulnerability(
                message.payload.get("code"),
                message.payload.get("vulnerability_type")
            )
        elif action == "assess_compliance":
            return await self.assess_compliance(
                message.payload.get("file_paths"),
                message.payload.get("framework")
            )
        elif action == "generate_remediation":
            return await self.generate_remediation_plan(
                message.payload.get("vulnerabilities")
            )
        else:
            return {"error": "Unknown action"}
            
    async def analyze_security(self, request: SecurityAnalysisRequest) -> SecurityAnalysisResult:
        """Comprehensive security analysis of code files."""
        start_time = datetime.utcnow()
        all_vulnerabilities = []
        
        try:
            for file_path in request.file_paths:
                # Read and parse file
                code_content = await self._read_file(file_path)
                
                # Perform vulnerability scanning
                vulnerabilities = await self._scan_vulnerabilities(code_content, file_path)
                all_vulnerabilities.extend(vulnerabilities)
                
                # Check for dependency vulnerabilities if requested
                if request.include_dependencies:
                    dep_vulnerabilities = await self._scan_dependencies(file_path)
                    all_vulnerabilities.extend(dep_vulnerabilities)
                    
            # Calculate security score
            security_score = await self._calculate_security_score(all_vulnerabilities)
            
            # Check compliance status
            compliance_status = {}
            if request.compliance_frameworks:
                for framework in request.compliance_frameworks:
                    compliance_status[framework] = await self._check_compliance(
                        all_vulnerabilities, framework
                    )
                    
            # Generate recommendations
            recommendations = await self._generate_security_recommendations(
                all_vulnerabilities, request.file_paths
            )
            
            # Perform risk assessment
            risk_assessment = await self._assess_security_risks(all_vulnerabilities)
            
            analysis_time = (datetime.utcnow() - start_time).total_seconds()
            
            return SecurityAnalysisResult(
                vulnerabilities=all_vulnerabilities,
                security_score=security_score,
                compliance_status=compliance_status,
                recommendations=recommendations,
                risk_assessment=risk_assessment,
                analysis_metadata={
                    "analysis_type": request.analysis_type,
                    "files_analyzed": len(request.file_paths),
                    "analysis_time": analysis_time,
                    "total_vulnerabilities": len(all_vulnerabilities)
                }
            )
            
        except Exception as e:
            self.logger.error(f"Security analysis failed: {str(e)}")
            raise
            
    async def _scan_vulnerabilities(self, code: str, file_path: str) -> List[SecurityVulnerability]:
        """Scan code for security vulnerabilities."""
        vulnerabilities = []
        
        # SQL Injection detection
        sql_vulns = await self._detect_sql_injection(code, file_path)
        vulnerabilities.extend(sql_vulns)
        
        # XSS detection
        xss_vulns = await self._detect_xss(code, file_path)
        vulnerabilities.extend(xss_vulns)
        
        # Authentication/Authorization flaws
        auth_vulns = await self._detect_auth_flaws(code, file_path)
        vulnerabilities.extend(auth_vulns)
        
        # Cryptographic weaknesses
        crypto_vulns = await self._detect_crypto_weaknesses(code, file_path)
        vulnerabilities.extend(crypto_vulns)
        
        # Security misconfigurations
        config_vulns = await self._detect_security_misconfigurations(code, file_path)
        vulnerabilities.extend(config_vulns)
        
        # Insecure deserialization
        deser_vulns = await self._detect_insecure_deserialization(code, file_path)
        vulnerabilities.extend(deser_vulns)
        
        return vulnerabilities
        
    async def _detect_sql_injection(self, code: str, file_path: str) -> List[SecurityVulnerability]:
        """Detect SQL injection vulnerabilities."""
        vulnerabilities = []
        
        # Pattern-based detection
        sql_injection_patterns = [
            r'execute\s*\(\s*["\'].*?%.*?["\']',  # String formatting in SQL
            r'cursor\.execute\s*\(\s*f["\'].*?\{.*?\}',  # f-string in SQL
            r'query\s*=\s*["\'].*?\+.*?["\']',  # String concatenation
            r'\.format\s*\(.*?\).*?execute',  # .format() with execute
        ]
        
        lines = code.split('\n')
        for line_num, line in enumerate(lines, 1):
            for pattern in sql_injection_patterns:
                if re.search(pattern, line, re.IGNORECASE):
                    vulnerabilities.append(SecurityVulnerability(
                        vulnerability_type=VulnerabilityType.SQL_INJECTION,
                        severity=RiskLevel.HIGH,
                        file_path=file_path,
                        line_number=line_num,
                        description="Potential SQL injection vulnerability detected",
                        evidence=line.strip(),
                        recommendation="Use parameterized queries or ORM methods",
                        cwe_id="CWE-89"
                    ))
                    
        return vulnerabilities
        
    async def _detect_xss(self, code: str, file_path: str) -> List[SecurityVulnerability]:
        """Detect Cross-Site Scripting (XSS) vulnerabilities."""
        vulnerabilities = []
        
        xss_patterns = [
            r'render_template_string\s*\(.*?\+.*?\)',  # Template injection
            r'\.innerHTML\s*=.*?(?:\+|\.format)',  # DOM manipulation
            r'document\.write\s*\(.*?\+.*?\)',  # Direct DOM writing
            r'eval\s*\(.*?request\..*?\)',  # Eval with user input
        ]
        
        lines = code.split('\n')
        for line_num, line in enumerate(lines, 1):
            for pattern in xss_patterns:
                if re.search(pattern, line, re.IGNORECASE):
                    vulnerabilities.append(SecurityVulnerability(
                        vulnerability_type=VulnerabilityType.XSS,
                        severity=RiskLevel.MEDIUM,
                        file_path=file_path,
                        line_number=line_num,
                        description="Potential XSS vulnerability detected",
                        evidence=line.strip(),
                        recommendation="Sanitize user input and use safe rendering methods",
                        cwe_id="CWE-79"
                    ))
                    
        return vulnerabilities
        
    async def _detect_auth_flaws(self, code: str, file_path: str) -> List[SecurityVulnerability]:
        """Detect authentication and authorization flaws."""
        vulnerabilities = []
        
        auth_patterns = [
            r'session\[.*?\]\s*=.*?without.*?verification',  # Session manipulation
            r'admin\s*=\s*True',  # Hardcoded admin privileges
            r'if.*?user\.is_admin.*?==.*?["\']admin["\']',  # Weak admin check
            r'password\s*==\s*["\'].*?["\']',  # Hardcoded passwords
        ]
        
        lines = code.split('\n')
        for line_num, line in enumerate(lines, 1):
            for pattern in auth_patterns:
                if re.search(pattern, line, re.IGNORECASE):
                    severity = RiskLevel.HIGH if "password" in line.lower() else RiskLevel.MEDIUM
                    vulnerabilities.append(SecurityVulnerability(
                        vulnerability_type=VulnerabilityType.AUTHENTICATION_BYPASS,
                        severity=severity,
                        file_path=file_path,
                        line_number=line_num,
                        description="Potential authentication/authorization flaw detected",
                        evidence=line.strip(),
                        recommendation="Implement proper authentication and authorization checks",
                        cwe_id="CWE-287"
                    ))
                    
        return vulnerabilities
        
    async def _detect_crypto_weaknesses(self, code: str, file_path: str) -> List[SecurityVulnerability]:
        """Detect cryptographic weaknesses."""
        vulnerabilities = []
        
        crypto_patterns = [
            r'md5\s*\(',  # Weak hashing
            r'sha1\s*\(',  # Weak hashing
            r'DES\s*\(',  # Weak encryption
            r'Random\s*\(\)',  # Weak randomness
            r'hardcoded.*?key',  # Hardcoded keys
        ]
        
        lines = code.split('\n')
        for line_num, line in enumerate(lines, 1):
            for pattern in crypto_patterns:
                if re.search(pattern, line, re.IGNORECASE):
                    vulnerabilities.append(SecurityVulnerability(
                        vulnerability_type=VulnerabilityType.CRYPTO_WEAKNESS,
                        severity=RiskLevel.MEDIUM,
                        file_path=file_path,
                        line_number=line_num,
                        description="Weak cryptographic implementation detected",
                        evidence=line.strip(),
                        recommendation="Use strong cryptographic algorithms and secure key management",
                        cwe_id="CWE-327"
                    ))
                    
        return vulnerabilities
        
    async def _calculate_security_score(self, vulnerabilities: List[SecurityVulnerability]) -> float:
        """Calculate overall security score (0-100)."""
        if not vulnerabilities:
            return 100.0
            
        total_impact = 0
        for vuln in vulnerabilities:
            if vuln.severity == RiskLevel.CRITICAL:
                total_impact += 20
            elif vuln.severity == RiskLevel.HIGH:
                total_impact += 10
            elif vuln.severity == RiskLevel.MEDIUM:
                total_impact += 5
            else:  # LOW
                total_impact += 1
                
        # Score decreases based on total impact
        score = max(0, 100 - total_impact)
        return score
        
    async def _generate_security_recommendations(self, vulnerabilities: List[SecurityVulnerability], file_paths: List[str]) -> List[str]:
        """Generate security improvement recommendations."""
        recommendations = []
        
        # Group vulnerabilities by type
        vuln_types = {}
        for vuln in vulnerabilities:
            vuln_type = vuln.vulnerability_type
            if vuln_type not in vuln_types:
                vuln_types[vuln_type] = []
            vuln_types[vuln_type].append(vuln)
            
        # Generate type-specific recommendations
        for vuln_type, vulns in vuln_types.items():
            count = len(vulns)
            if vuln_type == VulnerabilityType.SQL_INJECTION:
                recommendations.append(f"Address {count} SQL injection vulnerabilities by using parameterized queries")
            elif vuln_type == VulnerabilityType.XSS:
                recommendations.append(f"Fix {count} XSS vulnerabilities by implementing input sanitization")
            elif vuln_type == VulnerabilityType.CRYPTO_WEAKNESS:
                recommendations.append(f"Upgrade {count} weak cryptographic implementations to secure algorithms")
                
        # General recommendations
        if len(vulnerabilities) > 10:
            recommendations.append("Consider implementing automated security testing in CI/CD pipeline")
            
        recommendations.append("Regular security code reviews and penetration testing recommended")
        
        return recommendations
```

2. **Performance Agent** (`app/agents/performance_agent.py`):
```python
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import ast
import re
from datetime import datetime

from app.agents.base_agent import BaseAgent, AgentCapability
from app.models.domain.performance import PerformanceIssue, PerformanceReport, OptimizationLevel

class PerformanceIssueType(Enum):
    ALGORITHMIC_COMPLEXITY = "algorithmic_complexity"
    MEMORY_LEAK = "memory_leak"
    INEFFICIENT_QUERY = "inefficient_query"
    BLOCKING_OPERATION = "blocking_operation"
    EXCESSIVE_LOOPS = "excessive_loops"
    LARGE_OBJECT_CREATION = "large_object_creation"
    SYNCHRONOUS_IO = "synchronous_io"
    CACHE_MISS = "cache_miss"
    DATABASE_N_PLUS_ONE = "database_n_plus_one"
    INEFFICIENT_SERIALIZATION = "inefficient_serialization"

@dataclass
class PerformanceAnalysisRequest:
    file_paths: List[str]
    analysis_depth: str  # "surface", "deep", "comprehensive"
    include_profiling: bool = False
    benchmark_against: Optional[str] = None
    optimization_targets: List[str] = None

@dataclass
class PerformanceAnalysisResult:
    issues: List[PerformanceIssue]
    performance_score: float
    optimization_opportunities: List[Dict[str, Any]]
    estimated_improvements: Dict[str, float]
    recommendations: List[str]
    analysis_metadata: Dict[str, Any]

class PerformanceAgent(BaseAgent):
    def __init__(self):
        capabilities = [
            AgentCapability("performance_analysis", "1.0", 10, {"supports_profiling": True}),
            AgentCapability("complexity_analysis", "1.0", 9, {"supports_big_o": True}),
            AgentCapability("optimization_recommendations", "1.0", 8, {"supports_automation": True}),
            AgentCapability("benchmarking", "1.0", 7, {"supports_comparison": True})
        ]
        super().__init__("performance_agent", "performance", capabilities)
        
        self.complexity_patterns = self._load_complexity_patterns()
        self.optimization_rules = self._load_optimization_rules()
        
    async def handle_message(self, message) -> Optional[Any]:
        """Handle performance analysis requests."""
        action = message.payload.get("action")
        
        if action == "analyze_performance":
            request = PerformanceAnalysisRequest(**message.payload.get("request", {}))
            result = await self.analyze_performance(request)
            return result.__dict__
        elif action == "analyze_complexity":
            return await self.analyze_algorithmic_complexity(
                message.payload.get("code"),
                message.payload.get("function_name")
            )
        elif action == "suggest_optimizations":
            return await self.suggest_optimizations(
                message.payload.get("code"),
                message.payload.get("performance_target")
            )
        else:
            return {"error": "Unknown action"}
            
    async def analyze_performance(self, request: PerformanceAnalysisRequest) -> PerformanceAnalysisResult:
        """Comprehensive performance analysis."""
        start_time = datetime.utcnow()
        all_issues = []
        
        try:
            for file_path in request.file_paths:
                code_content = await self._read_file(file_path)
                
                # Analyze algorithmic complexity
                complexity_issues = await self._analyze_complexity(code_content, file_path)
                all_issues.extend(complexity_issues)
                
                # Detect performance anti-patterns
                pattern_issues = await self._detect_performance_patterns(code_content, file_path)
                all_issues.extend(pattern_issues)
                
                # Analyze I/O operations
                io_issues = await self._analyze_io_operations(code_content, file_path)
                all_issues.extend(io_issues)
                
                # Check database operations
                db_issues = await self._analyze_database_operations(code_content, file_path)
                all_issues.extend(db_issues)
                
            # Calculate performance score
            performance_score = await self._calculate_performance_score(all_issues)
            
            # Generate optimization opportunities
            optimization_opportunities = await self._identify_optimization_opportunities(
                all_issues, request.file_paths
            )
            
            # Estimate potential improvements
            estimated_improvements = await self._estimate_improvements(
                optimization_opportunities
            )
            
            # Generate recommendations
            recommendations = await self._generate_performance_recommendations(
                all_issues, optimization_opportunities
            )
            
            analysis_time = (datetime.utcnow() - start_time).total_seconds()
            
            return PerformanceAnalysisResult(
                issues=all_issues,
                performance_score=performance_score,
                optimization_opportunities=optimization_opportunities,
                estimated_improvements=estimated_improvements,
                recommendations=recommendations,
                analysis_metadata={
                    "analysis_depth": request.analysis_depth,
                    "files_analyzed": len(request.file_paths),
                    "analysis_time": analysis_time,
                    "total_issues": len(all_issues)
                }
            )
            
        except Exception as e:
            self.logger.error(f"Performance analysis failed: {str(e)}")
            raise
            
    async def _analyze_complexity(self, code: str, file_path: str) -> List[PerformanceIssue]:
        """Analyze algorithmic complexity of functions."""
        issues = []
        
        try:
            tree = ast.parse(code)
            
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    complexity = await self._calculate_function_complexity(node)
                    
                    if complexity['time_complexity'] == 'O(n²)' or complexity['time_complexity'] == 'O(n³)':
                        issues.append(PerformanceIssue(
                            issue_type=PerformanceIssueType.ALGORITHMIC_COMPLEXITY,
                            severity="HIGH",
                            file_path=file_path,
                            line_number=node.lineno,
                            function_name=node.name,
                            description=f"Function has {complexity['time_complexity']} time complexity",
                            impact_score=complexity.get('impact_score', 7),
                            suggested_fix="Consider optimizing algorithm or data structure",
                            complexity_details=complexity
                        ))
                        
        except SyntaxError:
            pass
            
        return issues
        
    async def _calculate_function_complexity(self, func_node: ast.FunctionDef) -> Dict[str, Any]:
        """Calculate Big O complexity for a function."""
        nested_loops = 0
        recursive_calls = 0
        
        for node in ast.walk(func_node):
            if isinstance(node, ast.For) or isinstance(node, ast.While):
                # Check for nested loops
                nested_loops += 1
            elif isinstance(node, ast.Call):
                if isinstance(node.func, ast.Name) and node.func.id == func_node.name:
                    recursive_calls += 1
                    
        # Simple complexity estimation
        if recursive_calls > 0:
            time_complexity = "O(2^n)"  # Exponential for simple recursion
            impact_score = 9
        elif nested_loops >= 2:
            time_complexity = "O(n²)"
            impact_score = 7
        elif nested_loops >= 3:
            time_complexity = "O(n³)"
            impact_score = 8
        elif nested_loops == 1:
            time_complexity = "O(n)"
            impact_score = 3
        else:
            time_complexity = "O(1)"
            impact_score = 1
            
        return {
            "time_complexity": time_complexity,
            "space_complexity": "O(1)",  # Simplified
            "nested_loops": nested_loops,
            "recursive_calls": recursive_calls,
            "impact_score": impact_score
        }
```

3. **Testing Agent** (`app/agents/testing_agent.py`):
```python
from typing import Dict, Any, List, Optional
from dataclasses import dataclass
import ast
import re
from datetime import datetime

from app.agents.base_agent import BaseAgent, AgentCapability
from app.models.domain.testing import TestCase, TestSuite, CoverageReport

@dataclass
class TestGenerationRequest:
    file_paths: List[str]
    test_types: List[str]  # ["unit", "integration", "e2e"]
    coverage_target: float = 80.0
    include_edge_cases: bool = True
    mock_external_dependencies: bool = True

@dataclass
class TestGenerationResult:
    test_suites: List[TestSuite]
    coverage_estimate: float
    test_quality_score: float
    recommendations: List[str]
    generation_metadata: Dict[str, Any]

class TestingAgent(BaseAgent):
    def __init__(self):
        capabilities = [
            AgentCapability("test_generation", "1.0", 10, {"supports_multiple_frameworks": True}),
            AgentCapability("coverage_analysis", "1.0", 9, {"supports_gap_detection": True}),
            AgentCapability("edge_case_detection", "1.0", 8, {"supports_boundary_testing": True}),
            AgentCapability("mock_generation", "1.0", 7, {"supports_dependency_mocking": True})
        ]
        super().__init__("testing_agent", "testing", capabilities)
        
    async def handle_message(self, message) -> Optional[Any]:
        """Handle test generation requests."""
        action = message.payload.get("action")
        
        if action == "generate_tests":
            request = TestGenerationRequest(**message.payload.get("request", {}))
            result = await self.generate_tests(request)
            return result.__dict__
        elif action == "analyze_coverage":
            return await self.analyze_test_coverage(
                message.payload.get("source_files"),
                message.payload.get("test_files")
            )
        elif action == "suggest_test_improvements":
            return await self.suggest_test_improvements(
                message.payload.get("test_code")
            )
        else:
            return {"error": "Unknown action"}
            
    async def generate_tests(self, request: TestGenerationRequest) -> TestGenerationResult:
        """Generate comprehensive test suites."""
        start_time = datetime.utcnow()
        test_suites = []
        
        try:
            for file_path in request.file_paths:
                code_content = await self._read_file(file_path)
                
                # Parse code structure
                code_structure = await self._parse_code_structure(code_content)
                
                # Generate unit tests
                if "unit" in request.test_types:
                    unit_tests = await self._generate_unit_tests(
                        code_structure, file_path, request
                    )
                    test_suites.extend(unit_tests)
                    
                # Generate integration tests
                if "integration" in request.test_types:
                    integration_tests = await self._generate_integration_tests(
                        code_structure, file_path, request
                    )
                    test_suites.extend(integration_tests)
                    
            # Estimate coverage
            coverage_estimate = await self._estimate_coverage(test_suites, request.file_paths)
            
            # Calculate test quality score
            test_quality_score = await self._calculate_test_quality(test_suites)
            
            # Generate recommendations
            recommendations = await self._generate_test_recommendations(
                test_suites, coverage_estimate, request.coverage_target
            )
            
            generation_time = (datetime.utcnow() - start_time).total_seconds()
            
            return TestGenerationResult(
                test_suites=test_suites,
                coverage_estimate=coverage_estimate,
                test_quality_score=test_quality_score,
                recommendations=recommendations,
                generation_metadata={
                    "generation_time": generation_time,
                    "files_processed": len(request.file_paths),
                    "total_test_cases": sum(len(suite.test_cases) for suite in test_suites)
                }
            )
            
        except Exception as e:
            self.logger.error(f"Test generation failed: {str(e)}")
            raise
            
    async def _generate_unit_tests(self, code_structure: Dict, file_path: str, request: TestGenerationRequest) -> List[TestSuite]:
        """Generate unit tests for functions and classes."""
        test_suites = []
        
        for class_info in code_structure.get("classes", []):
            class_test_suite = TestSuite(
                name=f"Test{class_info['name']}",
                file_path=f"test_{file_path.split('/')[-1]}",
                test_cases=[]
            )
            
            for method_info in class_info.get("methods", []):
                # Generate test cases for each method
                test_cases = await self._generate_method_test_cases(
                    class_info, method_info, request
                )
                class_test_suite.test_cases.extend(test_cases)
                
            test_suites.append(class_test_suite)
            
        return test_suites
        
    async def _generate_method_test_cases(self, class_info: Dict, method_info: Dict, request: TestGenerationRequest) -> List[TestCase]:
        """Generate test cases for a specific method."""
        test_cases = []
        
        # Basic happy path test
        test_cases.append(TestCase(
            name=f"test_{method_info['name']}_success",
            description=f"Test successful execution of {method_info['name']}",
            test_code=await self._generate_success_test_code(class_info, method_info),
            assertions=await self._generate_assertions(method_info),
            setup_code=await self._generate_setup_code(class_info, method_info),
            teardown_code=await self._generate_teardown_code(class_info, method_info)
        ))
        
        # Edge case tests
        if request.include_edge_cases:
            edge_case_tests = await self._generate_edge_case_tests(class_info, method_info)
            test_cases.extend(edge_case_tests)
            
        # Error condition tests
        error_tests = await self._generate_error_tests(class_info, method_info)
        test_cases.extend(error_tests)
        
        return test_cases
```

4. **Documentation Agent** (`app/agents/documentation_agent.py`):
```python
from typing import Dict, Any, List, Optional
from dataclasses import dataclass
import ast
import re
from datetime import datetime

from app.agents.base_agent import BaseAgent, AgentCapability
from app.models.domain.documentation import DocumentationSection, DocumentationReport

@dataclass
class DocumentationRequest:
    file_paths: List[str]
    documentation_types: List[str]  # ["api", "readme", "comments", "architecture"]
    target_audience: str  # "developers", "users", "maintainers"
    include_examples: bool = True
    format: str = "markdown"

@dataclass
class DocumentationResult:
    sections: List[DocumentationSection]
    quality_score: float
    completeness_score: float
    recommendations: List[str]
    generation_metadata: Dict[str, Any]

class DocumentationAgent(BaseAgent):
    def __init__(self):
        capabilities = [
            AgentCapability("api_documentation", "1.0", 10, {"supports_openapi": True}),
            AgentCapability("code_documentation", "1.0", 9, {"supports_docstrings": True}),
            AgentCapability("user_documentation", "1.0", 8, {"supports_tutorials": True}),
            AgentCapability("architecture_documentation", "1.0", 7, {"supports_diagrams": True})
        ]
        super().__init__("documentation_agent", "documentation", capabilities)
        
    async def handle_message(self, message) -> Optional[Any]:
        """Handle documentation generation requests."""
        action = message.payload.get("action")
        
        if action == "generate_documentation":
            request = DocumentationRequest(**message.payload.get("request", {}))
            result = await self.generate_documentation(request)
            return result.__dict__
        elif action == "analyze_documentation_gaps":
            return await self.analyze_documentation_gaps(
                message.payload.get("file_paths")
            )
        elif action == "improve_existing_docs":
            return await self.improve_existing_documentation(
                message.payload.get("existing_docs"),
                message.payload.get("code_files")
            )
        else:
            return {"error": "Unknown action"}
            
    async def generate_documentation(self, request: DocumentationRequest) -> DocumentationResult:
        """Generate comprehensive documentation."""
        start_time = datetime.utcnow()
        sections = []
        
        try:
            # Generate API documentation
            if "api" in request.documentation_types:
                api_sections = await self._generate_api_documentation(request.file_paths)
                sections.extend(api_sections)
                
            # Generate README documentation
            if "readme" in request.documentation_types:
                readme_section = await self._generate_readme_documentation(request.file_paths)
                sections.append(readme_section)
                
            # Generate code comments
            if "comments" in request.documentation_types:
                comment_sections = await self._generate_code_comments(request.file_paths)
                sections.extend(comment_sections)
                
            # Generate architecture documentation
            if "architecture" in request.documentation_types:
                arch_section = await self._generate_architecture_documentation(request.file_paths)
                sections.append(arch_section)
                
            # Calculate quality scores
            quality_score = await self._calculate_documentation_quality(sections)
            completeness_score = await self._calculate_completeness(sections, request.file_paths)
            
            # Generate recommendations
            recommendations = await self._generate_documentation_recommendations(
                sections, quality_score, completeness_score
            )
            
            generation_time = (datetime.utcnow() - start_time).total_seconds()
            
            return DocumentationResult(
                sections=sections,
                quality_score=quality_score,
                completeness_score=completeness_score,
                recommendations=recommendations,
                generation_metadata={
                    "generation_time": generation_time,
                    "files_processed": len(request.file_paths),
                    "sections_generated": len(sections)
                }
            )
            
        except Exception as e:
            self.logger.error(f"Documentation generation failed: {str(e)}")
            raise
```

## Dependencies
- Task 031: Multi-Agent Coordination Framework
- Task 032: Context Builder Agent
- Task 033: Retrieval Agent
- Task 006: File Processing System
- Task 012: Code Parsing

## Estimated Time
24-28 hours

## Required Skills
- Security analysis and vulnerability assessment
- Performance optimization techniques
- Test automation and generation
- Documentation best practices
- Domain expertise in each specialization
- Integration with multi-agent systems