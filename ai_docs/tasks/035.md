# Task 035: Advanced Memory System Implementation

## Overview
Implement the Advanced Memory System with multi-tier memory architecture, intelligent pruning, user interaction learning, and context evolution. This system will provide sophisticated memory management capabilities that learn and adapt to user patterns while maintaining optimal performance.

## Success Criteria
- [ ] Multi-tier memory system (hot, warm, cold, archived) functions correctly
- [ ] Intelligent pruning algorithms maintain performance while preserving important context
- [ ] User interaction learning improves memory relevance over time
- [ ] Context evolution tracks and adapts to changing user patterns
- [ ] Memory system achieves >95% cache hit rate for frequently accessed data
- [ ] Pruning maintains <100ms response time for memory operations

## Test First Approach

### Tests to Write BEFORE Implementation:

1. **Multi-Tier Memory Tests** (`tests/backend/unit/test_multi_tier_memory.py`):
```python
def test_memory_tier_management():
    """Test memory tier promotion and demotion."""
    # Test hot tier for frequently accessed items
    # Test warm tier for moderately accessed items
    # Test cold tier for rarely accessed items
    # Test archived tier for historical data
    # Test automatic tier promotion/demotion

def test_tier_performance_characteristics():
    """Test performance across memory tiers."""
    # Test hot tier <10ms access time
    # Test warm tier <50ms access time
    # Test cold tier <200ms access time
    # Test archived tier <1000ms access time
    # Test tier capacity limits

def test_memory_eviction_policies():
    """Test memory eviction algorithms."""
    # Test LRU eviction policy
    # Test LFU eviction policy
    # Test TTL-based eviction
    # Test intelligent eviction with context scoring
    # Test cross-tier eviction coordination
```

2. **Intelligent Pruning Tests** (`tests/backend/unit/test_intelligent_pruning.py`):
```python
def test_pruning_algorithms():
    """Test various pruning strategies."""
    # Test recency-based pruning
    # Test frequency-based pruning
    # Test relevance-based pruning
    # Test size-based pruning
    # Test hybrid pruning strategies

def test_pruning_performance():
    """Test pruning operation performance."""
    # Test pruning completes in <100ms
    # Test memory usage reduction after pruning
    # Test preservation of important context
    # Test pruning frequency optimization
    # Test background vs foreground pruning

def test_context_preservation():
    """Test important context preservation during pruning."""
    # Test high-value context retention
    # Test user-specified preservation rules
    # Test semantic similarity preservation
    # Test relationship preservation
    # Test metadata preservation
```

3. **User Interaction Learning Tests** (`tests/backend/unit/test_interaction_learning.py`):
```python
def test_interaction_pattern_detection():
    """Test detection of user interaction patterns."""
    # Test query pattern recognition
    # Test access pattern analysis
    # Test temporal pattern detection
    # Test context preference learning
    # Test feedback loop optimization

def test_learning_model_adaptation():
    """Test adaptive learning model updates."""
    # Test model parameter updates from interactions
    # Test reinforcement learning from user feedback
    # Test pattern recognition accuracy improvement
    # Test personalization effectiveness
    # Test learning convergence rates

def test_context_relevance_scoring():
    """Test context relevance scoring improvements."""
    # Test score accuracy improvement over time
    # Test personalized relevance calculations
    # Test multi-factor relevance scoring
    # Test real-time score updates
    # Test score prediction accuracy
```

## Implementation Details

1. **Memory System Core** (`app/memory/memory_system.py`):
```python
from typing import Dict, Any, List, Optional, Set, Tuple
from dataclasses import dataclass, field
from enum import Enum
import asyncio
import time
import json
from datetime import datetime, timedelta
import numpy as np

class MemoryTier(Enum):
    HOT = "hot"        # <10ms access, frequently used
    WARM = "warm"      # <50ms access, moderately used
    COLD = "cold"      # <200ms access, rarely used
    ARCHIVED = "archived"  # <1000ms access, historical

class EvictionPolicy(Enum):
    LRU = "lru"           # Least Recently Used
    LFU = "lfu"           # Least Frequently Used
    TTL = "ttl"           # Time To Live
    INTELLIGENT = "intelligent"  # AI-driven eviction

@dataclass
class MemoryItem:
    key: str
    value: Any
    metadata: Dict[str, Any]
    tier: MemoryTier
    created_at: datetime
    last_accessed: datetime
    access_count: int = 0
    relevance_score: float = 0.0
    size_bytes: int = 0
    user_interactions: List[Dict[str, Any]] = field(default_factory=list)
    
    def update_access(self):
        """Update access metadata."""
        self.last_accessed = datetime.utcnow()
        self.access_count += 1
        
    def record_interaction(self, interaction_type: str, context: Dict[str, Any]):
        """Record user interaction with this memory item."""
        self.user_interactions.append({
            "type": interaction_type,
            "timestamp": datetime.utcnow(),
            "context": context
        })

@dataclass
class TierConfiguration:
    max_items: int
    max_size_mb: int
    access_time_target_ms: int
    eviction_policy: EvictionPolicy
    promotion_threshold: float
    demotion_threshold: float

class AdvancedMemorySystem:
    def __init__(self):
        self.tiers: Dict[MemoryTier, Dict[str, MemoryItem]] = {
            tier: {} for tier in MemoryTier
        }
        
        self.tier_configs = {
            MemoryTier.HOT: TierConfiguration(
                max_items=10000,
                max_size_mb=512,
                access_time_target_ms=10,
                eviction_policy=EvictionPolicy.LFU,
                promotion_threshold=0.9,
                demotion_threshold=0.3
            ),
            MemoryTier.WARM: TierConfiguration(
                max_items=50000,
                max_size_mb=1024,
                access_time_target_ms=50,
                eviction_policy=EvictionPolicy.LRU,
                promotion_threshold=0.8,
                demotion_threshold=0.2
            ),
            MemoryTier.COLD: TierConfiguration(
                max_items=200000,
                max_size_mb=2048,
                access_time_target_ms=200,
                eviction_policy=EvictionPolicy.TTL,
                promotion_threshold=0.7,
                demotion_threshold=0.1
            ),
            MemoryTier.ARCHIVED: TierConfiguration(
                max_items=1000000,
                max_size_mb=8192,
                access_time_target_ms=1000,
                eviction_policy=EvictionPolicy.INTELLIGENT,
                promotion_threshold=0.6,
                demotion_threshold=0.0
            )
        }
        
        self.interaction_learner = InteractionLearner()
        self.pruning_engine = IntelligentPruningEngine()
        self.context_evolution = ContextEvolutionTracker()
        
        # Performance metrics
        self.access_stats = {
            "hits": 0,
            "misses": 0,
            "tier_hits": {tier: 0 for tier in MemoryTier},
            "access_times": [],
            "evictions": {tier: 0 for tier in MemoryTier}
        }
        
        # Start background tasks
        asyncio.create_task(self._background_maintenance())
        
    async def get(self, key: str, context: Dict[str, Any] = None) -> Optional[Any]:
        """Retrieve item from memory with tier management."""
        start_time = time.time()
        
        try:
            # Search through tiers (hot to cold)
            for tier in [MemoryTier.HOT, MemoryTier.WARM, MemoryTier.COLD, MemoryTier.ARCHIVED]:
                if key in self.tiers[tier]:
                    item = self.tiers[tier][key]
                    
                    # Update access metadata
                    item.update_access()
                    if context:
                        item.record_interaction("get", context)
                    
                    # Learn from interaction
                    await self.interaction_learner.record_access(key, tier, context)
                    
                    # Consider promotion
                    await self._consider_promotion(key, item, tier)
                    
                    # Update stats
                    self.access_stats["hits"] += 1
                    self.access_stats["tier_hits"][tier] += 1
                    
                    access_time = (time.time() - start_time) * 1000
                    self.access_stats["access_times"].append(access_time)
                    
                    return item.value
                    
            # Cache miss
            self.access_stats["misses"] += 1
            return None
            
        except Exception as e:
            print(f"Memory get error: {e}")
            return None
            
    async def put(self, key: str, value: Any, metadata: Dict[str, Any] = None, 
                  tier: MemoryTier = None) -> bool:
        """Store item in memory with intelligent tier placement."""
        try:
            # Determine optimal tier if not specified
            if tier is None:
                tier = await self._determine_optimal_tier(key, value, metadata)
                
            # Create memory item
            item = MemoryItem(
                key=key,
                value=value,
                metadata=metadata or {},
                tier=tier,
                created_at=datetime.utcnow(),
                last_accessed=datetime.utcnow(),
                size_bytes=len(str(value).encode('utf-8'))
            )
            
            # Remove from other tiers if exists
            await self._remove_from_other_tiers(key, tier)
            
            # Check capacity and evict if necessary
            await self._ensure_capacity(tier, item.size_bytes)
            
            # Store in tier
            self.tiers[tier][key] = item
            
            # Update relevance score
            item.relevance_score = await self.interaction_learner.calculate_relevance(
                key, value, metadata
            )
            
            return True
            
        except Exception as e:
            print(f"Memory put error: {e}")
            return False
            
    async def _determine_optimal_tier(self, key: str, value: Any, 
                                    metadata: Dict[str, Any]) -> MemoryTier:
        """Determine optimal tier for new item based on patterns."""
        # Use interaction learner to predict optimal tier
        predicted_tier = await self.interaction_learner.predict_optimal_tier(
            key, value, metadata
        )
        
        # Consider size constraints
        size_bytes = len(str(value).encode('utf-8'))
        
        # Start with predicted tier, fallback to less constrained tiers if needed
        for tier in [predicted_tier, MemoryTier.WARM, MemoryTier.COLD, MemoryTier.ARCHIVED]:
            config = self.tier_configs[tier]
            current_size = sum(item.size_bytes for item in self.tiers[tier].values())
            
            if current_size + size_bytes <= config.max_size_mb * 1024 * 1024:
                return tier
                
        return MemoryTier.ARCHIVED  # Fallback
        
    async def _consider_promotion(self, key: str, item: MemoryItem, current_tier: MemoryTier):
        """Consider promoting item to higher tier based on usage patterns."""
        if current_tier == MemoryTier.HOT:
            return  # Already at highest tier
            
        config = self.tier_configs[current_tier]
        
        # Calculate promotion score based on multiple factors
        recency_score = self._calculate_recency_score(item)
        frequency_score = self._calculate_frequency_score(item)
        relevance_score = item.relevance_score
        
        combined_score = (recency_score * 0.3 + frequency_score * 0.4 + relevance_score * 0.3)
        
        if combined_score >= config.promotion_threshold:
            target_tier = self._get_higher_tier(current_tier)
            await self._promote_item(key, item, current_tier, target_tier)
            
    async def _promote_item(self, key: str, item: MemoryItem, 
                          from_tier: MemoryTier, to_tier: MemoryTier):
        """Promote item to higher tier."""
        # Ensure capacity in target tier
        await self._ensure_capacity(to_tier, item.size_bytes)
        
        # Move item
        del self.tiers[from_tier][key]
        item.tier = to_tier
        self.tiers[to_tier][key] = item
        
    def _calculate_recency_score(self, item: MemoryItem) -> float:
        """Calculate recency score (0-1)."""
        hours_since_access = (datetime.utcnow() - item.last_accessed).total_seconds() / 3600
        return max(0, 1 - (hours_since_access / 24))  # Decay over 24 hours
        
    def _calculate_frequency_score(self, item: MemoryItem) -> float:
        """Calculate frequency score (0-1)."""
        # Normalize access count (log scale)
        return min(1.0, np.log(item.access_count + 1) / np.log(100))
        
    async def _ensure_capacity(self, tier: MemoryTier, additional_bytes: int):
        """Ensure tier has capacity for additional data."""
        config = self.tier_configs[tier]
        current_items = len(self.tiers[tier])
        current_size = sum(item.size_bytes for item in self.tiers[tier].values())
        
        # Check item count limit
        if current_items >= config.max_items:
            await self._evict_items(tier, count=1)
            
        # Check size limit
        max_size_bytes = config.max_size_mb * 1024 * 1024
        if current_size + additional_bytes > max_size_bytes:
            bytes_to_free = (current_size + additional_bytes) - max_size_bytes
            await self._evict_items(tier, bytes_to_free=bytes_to_free)
            
    async def _evict_items(self, tier: MemoryTier, count: int = None, 
                         bytes_to_free: int = None):
        """Evict items from tier based on eviction policy."""
        config = self.tier_configs[tier]
        items = list(self.tiers[tier].values())
        
        if not items:
            return
            
        if config.eviction_policy == EvictionPolicy.LRU:
            # Sort by last accessed (oldest first)
            items.sort(key=lambda x: x.last_accessed)
        elif config.eviction_policy == EvictionPolicy.LFU:
            # Sort by access count (least frequent first)
            items.sort(key=lambda x: x.access_count)
        elif config.eviction_policy == EvictionPolicy.TTL:
            # Sort by creation time (oldest first)
            items.sort(key=lambda x: x.created_at)
        elif config.eviction_policy == EvictionPolicy.INTELLIGENT:
            # Use AI-based scoring
            items = await self.pruning_engine.score_items_for_eviction(items)
            
        # Evict items
        freed_bytes = 0
        evicted_count = 0
        
        for item in items:
            if count and evicted_count >= count:
                break
            if bytes_to_free and freed_bytes >= bytes_to_free:
                break
                
            # Consider demotion before eviction
            if tier != MemoryTier.ARCHIVED:
                lower_tier = self._get_lower_tier(tier)
                await self._promote_item(item.key, item, tier, lower_tier)
            else:
                # Actually evict from system
                del self.tiers[tier][item.key]
                self.access_stats["evictions"][tier] += 1
                
            freed_bytes += item.size_bytes
            evicted_count += 1
            
    def _get_higher_tier(self, tier: MemoryTier) -> MemoryTier:
        """Get the next higher tier."""
        tier_order = [MemoryTier.ARCHIVED, MemoryTier.COLD, MemoryTier.WARM, MemoryTier.HOT]
        current_index = tier_order.index(tier)
        if current_index < len(tier_order) - 1:
            return tier_order[current_index + 1]
        return tier
        
    def _get_lower_tier(self, tier: MemoryTier) -> MemoryTier:
        """Get the next lower tier."""
        tier_order = [MemoryTier.HOT, MemoryTier.WARM, MemoryTier.COLD, MemoryTier.ARCHIVED]
        current_index = tier_order.index(tier)
        if current_index < len(tier_order) - 1:
            return tier_order[current_index + 1]
        return tier
        
    async def _background_maintenance(self):
        """Background maintenance tasks."""
        while True:
            try:
                # Run maintenance every 5 minutes
                await asyncio.sleep(300)
                
                # Intelligent pruning
                await self.pruning_engine.run_pruning_cycle(self.tiers)
                
                # Context evolution tracking
                await self.context_evolution.analyze_patterns(self.tiers)
                
                # Update interaction models
                await self.interaction_learner.update_models()
                
                # Performance optimization
                await self._optimize_tier_configurations()
                
            except Exception as e:
                print(f"Background maintenance error: {e}")
                
    async def get_memory_stats(self) -> Dict[str, Any]:
        """Get comprehensive memory system statistics."""
        total_hits = self.access_stats["hits"]
        total_requests = total_hits + self.access_stats["misses"]
        hit_rate = total_hits / total_requests if total_requests > 0 else 0
        
        avg_access_time = (
            sum(self.access_stats["access_times"]) / len(self.access_stats["access_times"])
            if self.access_stats["access_times"] else 0
        )
        
        tier_stats = {}
        for tier in MemoryTier:
            items = self.tiers[tier]
            total_size = sum(item.size_bytes for item in items.values())
            tier_stats[tier.value] = {
                "item_count": len(items),
                "total_size_mb": total_size / (1024 * 1024),
                "hits": self.access_stats["tier_hits"][tier],
                "evictions": self.access_stats["evictions"][tier]
            }
            
        return {
            "hit_rate": hit_rate,
            "average_access_time_ms": avg_access_time,
            "total_requests": total_requests,
            "tier_stats": tier_stats,
            "learning_stats": await self.interaction_learner.get_stats(),
            "pruning_stats": await self.pruning_engine.get_stats()
        }
```

2. **Interaction Learning Engine** (`app/memory/interaction_learner.py`):
```python
from typing import Dict, Any, List, Optional
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from datetime import datetime, timedelta
import pickle
import asyncio

class InteractionLearner:
    def __init__(self):
        self.tier_predictor = RandomForestClassifier(n_estimators=100, random_state=42)
        self.relevance_predictor = LogisticRegression()
        
        self.interaction_history = []
        self.user_patterns = {
            "query_patterns": {},
            "access_patterns": {},
            "temporal_patterns": {},
            "context_preferences": {}
        }
        
        self.feature_extractors = {
            "text_features": self._extract_text_features,
            "temporal_features": self._extract_temporal_features,
            "context_features": self._extract_context_features,
            "user_features": self._extract_user_features
        }
        
        # Model performance tracking
        self.model_stats = {
            "tier_prediction_accuracy": 0.0,
            "relevance_prediction_accuracy": 0.0,
            "total_predictions": 0,
            "correct_predictions": 0
        }
        
    async def record_access(self, key: str, tier: MemoryTier, context: Dict[str, Any]):
        """Record user access for learning."""
        interaction = {
            "key": key,
            "tier": tier,
            "context": context,
            "timestamp": datetime.utcnow(),
            "features": await self._extract_all_features(key, context)
        }
        
        self.interaction_history.append(interaction)
        
        # Update pattern tracking
        await self._update_patterns(interaction)
        
        # Limit history size
        if len(self.interaction_history) > 10000:
            self.interaction_history = self.interaction_history[-8000:]
            
    async def predict_optimal_tier(self, key: str, value: Any, 
                                 metadata: Dict[str, Any]) -> MemoryTier:
        """Predict optimal tier for new item."""
        if len(self.interaction_history) < 100:
            return MemoryTier.WARM  # Default for insufficient data
            
        try:
            features = await self._extract_all_features(key, {
                "value": value,
                "metadata": metadata
            })
            
            # Predict tier
            tier_probs = self.tier_predictor.predict_proba([features])[0]
            predicted_tier_index = np.argmax(tier_probs)
            
            tier_mapping = [MemoryTier.HOT, MemoryTier.WARM, MemoryTier.COLD, MemoryTier.ARCHIVED]
            return tier_mapping[predicted_tier_index]
            
        except Exception as e:
            print(f"Tier prediction error: {e}")
            return MemoryTier.WARM
            
    async def calculate_relevance(self, key: str, value: Any, 
                                metadata: Dict[str, Any]) -> float:
        """Calculate relevance score for item."""
        try:
            features = await self._extract_all_features(key, {
                "value": value,
                "metadata": metadata
            })
            
            if hasattr(self.relevance_predictor, 'predict_proba'):
                relevance = self.relevance_predictor.predict_proba([features])[0][1]
            else:
                relevance = 0.5  # Default if model not trained
                
            return max(0.0, min(1.0, relevance))
            
        except Exception as e:
            print(f"Relevance calculation error: {e}")
            return 0.5
            
    async def _extract_all_features(self, key: str, context: Dict[str, Any]) -> List[float]:
        """Extract all features for ML models."""
        features = []
        
        for extractor_name, extractor_func in self.feature_extractors.items():
            try:
                extracted = extractor_func(key, context)
                features.extend(extracted)
            except Exception as e:
                print(f"Feature extraction error ({extractor_name}): {e}")
                # Add default features for this extractor
                features.extend([0.0] * 10)  # Adjust based on extractor
                
        return features
        
    def _extract_text_features(self, key: str, context: Dict[str, Any]) -> List[float]:
        """Extract text-based features."""
        features = []
        
        # Key features
        features.append(len(key))
        features.append(len(key.split()))
        features.append(1.0 if key.isupper() else 0.0)
        features.append(1.0 if key.islower() else 0.0)
        features.append(key.count('_'))
        features.append(key.count('-'))
        
        # Content features
        value_str = str(context.get("value", ""))
        features.append(len(value_str))
        features.append(len(value_str.split()))
        features.append(value_str.count('\n'))
        features.append(1.0 if any(word in value_str.lower() for word in 
                                 ['function', 'class', 'method', 'def']) else 0.0)
        
        return features
        
    def _extract_temporal_features(self, key: str, context: Dict[str, Any]) -> List[float]:
        """Extract temporal features."""
        now = datetime.utcnow()
        features = []
        
        # Time of day
        features.append(now.hour / 24.0)
        features.append(now.minute / 60.0)
        
        # Day of week
        features.append(now.weekday() / 7.0)
        
        # Historical access patterns for this key
        key_accesses = [h for h in self.interaction_history if h["key"] == key]
        features.append(len(key_accesses))
        
        if key_accesses:
            # Time since last access
            last_access = max(h["timestamp"] for h in key_accesses)
            hours_since = (now - last_access).total_seconds() / 3600
            features.append(min(1.0, hours_since / 24))  # Normalize to 0-1 over 24 hours
        else:
            features.append(1.0)  # Never accessed before
            
        # Access frequency patterns
        recent_accesses = [h for h in key_accesses 
                          if (now - h["timestamp"]).days <= 7]
        features.append(len(recent_accesses) / 7.0)  # Accesses per day in last week
        
        return features
        
    def _extract_context_features(self, key: str, context: Dict[str, Any]) -> List[float]:
        """Extract context-based features."""
        features = []
        
        # Context size and complexity
        context_str = str(context)
        features.append(len(context_str))
        features.append(len(context.get("metadata", {})))
        
        # Context type indicators
        features.append(1.0 if "query" in context else 0.0)
        features.append(1.0 if "file_path" in context else 0.0)
        features.append(1.0 if "code" in context else 0.0)
        features.append(1.0 if "documentation" in context else 0.0)
        
        # User context
        features.append(1.0 if "user_id" in context else 0.0)
        features.append(1.0 if "session_id" in context else 0.0)
        
        return features
        
    def _extract_user_features(self, key: str, context: Dict[str, Any]) -> List[float]:
        """Extract user behavior features."""
        features = []
        
        # User preference scores
        user_id = context.get("user_id", "default")
        user_prefs = self.user_patterns["context_preferences"].get(user_id, {})
        
        features.append(user_prefs.get("prefers_recent", 0.5))
        features.append(user_prefs.get("prefers_frequent", 0.5))
        features.append(user_prefs.get("prefers_detailed", 0.5))
        features.append(user_prefs.get("prefers_concise", 0.5))
        
        # Session patterns
        session_id = context.get("session_id", "default")
        features.append(1.0 if session_id in self.user_patterns["access_patterns"] else 0.0)
        
        return features
        
    async def _update_patterns(self, interaction: Dict[str, Any]):
        """Update learned user patterns."""
        key = interaction["key"]
        context = interaction["context"]
        timestamp = interaction["timestamp"]
        
        # Update query patterns
        if "query" in context:
            query = context["query"]
            if query not in self.user_patterns["query_patterns"]:
                self.user_patterns["query_patterns"][query] = {"count": 0, "last_seen": timestamp}
            self.user_patterns["query_patterns"][query]["count"] += 1
            self.user_patterns["query_patterns"][query]["last_seen"] = timestamp
            
        # Update access patterns
        user_id = context.get("user_id", "default")
        if user_id not in self.user_patterns["access_patterns"]:
            self.user_patterns["access_patterns"][user_id] = {}
        if key not in self.user_patterns["access_patterns"][user_id]:
            self.user_patterns["access_patterns"][user_id][key] = {"count": 0, "last_access": timestamp}
        self.user_patterns["access_patterns"][user_id][key]["count"] += 1
        self.user_patterns["access_patterns"][user_id][key]["last_access"] = timestamp
        
    async def update_models(self):
        """Update ML models with recent interaction data."""
        if len(self.interaction_history) < 100:
            return
            
        try:
            # Prepare training data
            features = []
            tier_labels = []
            relevance_labels = []
            
            for interaction in self.interaction_history[-1000:]:  # Use recent data
                features.append(interaction["features"])
                tier_labels.append(self._tier_to_index(interaction["tier"]))
                # Relevance based on access frequency (simplified)
                relevance_labels.append(1 if interaction["tier"] in [MemoryTier.HOT, MemoryTier.WARM] else 0)
                
            # Update tier predictor
            self.tier_predictor.fit(features, tier_labels)
            
            # Update relevance predictor
            self.relevance_predictor.fit(features, relevance_labels)
            
            # Update performance stats
            self.model_stats["total_predictions"] += len(features)
            
        except Exception as e:
            print(f"Model update error: {e}")
            
    def _tier_to_index(self, tier: MemoryTier) -> int:
        """Convert tier to index for ML model."""
        mapping = {
            MemoryTier.HOT: 0,
            MemoryTier.WARM: 1,
            MemoryTier.COLD: 2,
            MemoryTier.ARCHIVED: 3
        }
        return mapping.get(tier, 1)
        
    async def get_stats(self) -> Dict[str, Any]:
        """Get learning system statistics."""
        return {
            "interaction_count": len(self.interaction_history),
            "pattern_counts": {
                "query_patterns": len(self.user_patterns["query_patterns"]),
                "access_patterns": len(self.user_patterns["access_patterns"]),
                "temporal_patterns": len(self.user_patterns["temporal_patterns"])
            },
            "model_performance": self.model_stats
        }
```

3. **Intelligent Pruning Engine** (`app/memory/pruning_engine.py`):
```python
from typing import Dict, Any, List, Optional, Tuple
import numpy as np
from datetime import datetime, timedelta
import asyncio

class PruningStrategy(Enum):
    RECENCY = "recency"
    FREQUENCY = "frequency"  
    RELEVANCE = "relevance"
    SIZE = "size"
    HYBRID = "hybrid"

class IntelligentPruningEngine:
    def __init__(self):
        self.pruning_history = []
        self.preservation_rules = {}
        self.pruning_stats = {
            "total_pruned": 0,
            "bytes_freed": 0,
            "items_preserved": 0,
            "avg_pruning_time_ms": 0.0
        }
        
    async def run_pruning_cycle(self, tiers: Dict[MemoryTier, Dict[str, MemoryItem]]):
        """Run intelligent pruning across all tiers."""
        start_time = datetime.utcnow()
        
        try:
            for tier in MemoryTier:
                await self._prune_tier(tier, tiers[tier])
                
            # Update stats
            pruning_time = (datetime.utcnow() - start_time).total_seconds() * 1000
            self.pruning_stats["avg_pruning_time_ms"] = (
                (self.pruning_stats["avg_pruning_time_ms"] * len(self.pruning_history) + pruning_time)
                / (len(self.pruning_history) + 1)
            )
            
            self.pruning_history.append({
                "timestamp": start_time,
                "duration_ms": pruning_time,
                "items_processed": sum(len(tier_items) for tier_items in tiers.values())
            })
            
        except Exception as e:
            print(f"Pruning cycle error: {e}")
            
    async def _prune_tier(self, tier: MemoryTier, items: Dict[str, MemoryItem]):
        """Prune specific tier using intelligent strategies."""
        if not items:
            return
            
        # Calculate pruning targets based on tier health
        pruning_target = await self._calculate_pruning_target(tier, items)
        
        if pruning_target <= 0:
            return
            
        # Score all items for potential pruning
        scored_items = await self.score_items_for_eviction(list(items.values()))
        
        # Apply preservation rules
        items_to_prune = await self._apply_preservation_rules(scored_items, pruning_target)
        
        # Execute pruning
        for item in items_to_prune:
            if item.key in items:
                del items[item.key]
                self.pruning_stats["total_pruned"] += 1
                self.pruning_stats["bytes_freed"] += item.size_bytes
                
    async def score_items_for_eviction(self, items: List[MemoryItem]) -> List[MemoryItem]:
        """Score items for eviction priority (lower score = higher eviction priority)."""
        scored_items = []
        
        for item in items:
            score = await self._calculate_comprehensive_score(item)
            scored_items.append((item, score))
            
        # Sort by score (lowest first for eviction)
        scored_items.sort(key=lambda x: x[1])
        
        return [item for item, score in scored_items]
        
    async def _calculate_comprehensive_score(self, item: MemoryItem) -> float:
        """Calculate comprehensive retention score for item."""
        # Recency score (0-1, higher = more recent)
        hours_since_access = (datetime.utcnow() - item.last_accessed).total_seconds() / 3600
        recency_score = max(0, 1 - (hours_since_access / (24 * 7)))  # Decay over week
        
        # Frequency score (0-1, higher = more frequent)
        frequency_score = min(1.0, np.log(item.access_count + 1) / np.log(100))
        
        # Size penalty (0-1, higher = smaller)
        max_reasonable_size = 1024 * 1024  # 1MB
        size_score = max(0, 1 - (item.size_bytes / max_reasonable_size))
        
        # Relevance score (from ML model)
        relevance_score = item.relevance_score
        
        # User interaction score
        interaction_score = await self._calculate_interaction_score(item)
        
        # Semantic importance score
        semantic_score = await self._calculate_semantic_importance(item)
        
        # Weighted combination
        comprehensive_score = (
            recency_score * 0.25 +
            frequency_score * 0.25 +
            size_score * 0.1 +
            relevance_score * 0.2 +
            interaction_score * 0.1 +
            semantic_score * 0.1
        )
        
        return comprehensive_score
        
    async def _calculate_interaction_score(self, item: MemoryItem) -> float:
        """Calculate score based on user interactions."""
        if not item.user_interactions:
            return 0.0
            
        # Recent interactions are more valuable
        now = datetime.utcnow()
        interaction_scores = []
        
        for interaction in item.user_interactions:
            time_diff = (now - interaction["timestamp"]).total_seconds() / 3600
            decay_factor = max(0, 1 - (time_diff / (24 * 7)))  # Week decay
            
            # Different interaction types have different values
            type_multiplier = {
                "get": 1.0,
                "edit": 2.0,
                "bookmark": 1.5,
                "share": 1.3,
                "search": 0.8
            }.get(interaction["type"], 1.0)
            
            interaction_scores.append(decay_factor * type_multiplier)
            
        return min(1.0, sum(interaction_scores) / 10)  # Normalize
        
    async def _calculate_semantic_importance(self, item: MemoryItem) -> float:
        """Calculate semantic importance score."""
        # Analyze content for importance indicators
        content = str(item.value).lower()
        metadata = item.metadata
        
        importance_indicators = [
            "important", "critical", "urgent", "key", "main", "primary",
            "essential", "core", "fundamental", "crucial", "significant"
        ]
        
        # Check for importance keywords
        importance_score = sum(1 for indicator in importance_indicators if indicator in content)
        importance_score = min(1.0, importance_score / 5)
        
        # Check metadata for importance signals
        if metadata.get("priority") == "high":
            importance_score = max(importance_score, 0.8)
        elif metadata.get("priority") == "medium":
            importance_score = max(importance_score, 0.5)
            
        # Check for structural importance
        if metadata.get("type") in ["root", "index", "main", "config"]:
            importance_score = max(importance_score, 0.7)
            
        return importance_score
        
    async def _calculate_pruning_target(self, tier: MemoryTier, 
                                      items: Dict[str, MemoryItem]) -> int:
        """Calculate how many items should be pruned from tier."""
        if not items:
            return 0
            
        # Tier-specific thresholds
        thresholds = {
            MemoryTier.HOT: 0.9,      # Prune when 90% full
            MemoryTier.WARM: 0.85,    # Prune when 85% full
            MemoryTier.COLD: 0.8,     # Prune when 80% full
            MemoryTier.ARCHIVED: 0.75  # Prune when 75% full
        }
        
        threshold = thresholds.get(tier, 0.8)
        current_count = len(items)
        
        # Calculate based on access patterns
        inactive_items = [
            item for item in items.values()
            if (datetime.utcnow() - item.last_accessed).days > 30
        ]
        
        # Prune percentage of inactive items
        target_prune_count = int(len(inactive_items) * 0.3)
        
        return min(target_prune_count, current_count // 4)  # Max 25% per cycle
        
    async def _apply_preservation_rules(self, scored_items: List[MemoryItem], 
                                      target_count: int) -> List[MemoryItem]:
        """Apply preservation rules to protect important items."""
        items_to_prune = []
        preserved_count = 0
        
        for item in scored_items:
            if len(items_to_prune) >= target_count:
                break
                
            # Check preservation rules
            should_preserve = await self._should_preserve_item(item)
            
            if should_preserve:
                preserved_count += 1
                self.pruning_stats["items_preserved"] += 1
                continue
                
            items_to_prune.append(item)
            
        return items_to_prune
        
    async def _should_preserve_item(self, item: MemoryItem) -> bool:
        """Check if item should be preserved from pruning."""
        # Always preserve very recent items
        if (datetime.utcnow() - item.last_accessed).hours < 1:
            return True
            
        # Preserve high-frequency items
        if item.access_count > 50:
            return True
            
        # Preserve items with high relevance scores
        if item.relevance_score > 0.9:
            return True
            
        # Preserve items with important metadata
        if item.metadata.get("preserve", False):
            return True
            
        # Preserve items with recent user interactions
        if item.user_interactions:
            recent_interactions = [
                i for i in item.user_interactions
                if (datetime.utcnow() - i["timestamp"]).hours < 24
            ]
            if recent_interactions:
                return True
                
        return False
        
    async def get_stats(self) -> Dict[str, Any]:
        """Get pruning engine statistics."""
        return {
            "pruning_cycles": len(self.pruning_history),
            "total_pruned": self.pruning_stats["total_pruned"],
            "bytes_freed": self.pruning_stats["bytes_freed"],
            "items_preserved": self.pruning_stats["items_preserved"],
            "avg_pruning_time_ms": self.pruning_stats["avg_pruning_time_ms"]
        }
```

## Dependencies
- Task 031: Multi-Agent Coordination Framework
- Task 025: Redis Integration
- Task 008: Async Database Operations
- Task 030: Performance Monitoring
- Task 034: Specialized Domain Agents

## Estimated Time
22-26 hours

## Required Skills
- Advanced memory management techniques
- Machine learning and pattern recognition
- Multi-tier storage system design
- Performance optimization
- Intelligent caching strategies
- User behavior analysis
- Real-time system design