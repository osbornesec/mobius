# Task 047: Enterprise Support and Documentation Platform Implementation

## Overview
Implement a comprehensive enterprise support and documentation platform that provides intelligent help systems, automated documentation generation, knowledge base management, and enterprise-grade customer support workflows. This platform will reduce support burden and improve user experience through AI-powered assistance.

## Success Criteria
- [ ] AI-powered help system resolves >70% of user queries without human intervention
- [ ] Automated documentation generation maintains >95% accuracy and coverage
- [ ] Knowledge base search provides relevant results with <2 second response time
- [ ] Support ticket routing and escalation reduces resolution time by >50%
- [ ] Self-service capabilities handle >80% of common enterprise use cases
- [ ] Platform integrates with major helpdesk and CRM systems

## Test First Approach

### Tests to Write BEFORE Implementation:

1. **AI Help System Tests** (`tests/test_ai_help_system.py`):
```python
def test_query_understanding():
    """Test AI query understanding and classification."""
    # Test natural language query parsing
    # Test intent classification accuracy
    # Test entity extraction
    # Test context understanding
    # Test multi-turn conversation handling

def test_answer_generation():
    """Test automated answer generation."""
    # Test answer relevance >90%
    # Test answer accuracy >95%
    # Test response time <2 seconds
    # Test personalization based on user context
    # Test fallback to human support

def test_conversation_flow():
    """Test conversational AI capabilities."""
    # Test multi-turn dialogue management
    # Test context preservation
    # Test clarifying questions
    # Test escalation triggers
    # Test user satisfaction tracking
```

2. **Documentation Generation Tests** (`tests/test_doc_generation.py`):
```python
def test_automated_doc_creation():
    """Test automated documentation generation."""
    # Test code documentation extraction
    # Test API documentation generation
    # Test user guide creation
    # Test screenshot automation
    # Test documentation versioning

def test_content_quality():
    """Test documentation content quality."""
    # Test accuracy >95%
    # Test completeness coverage
    # Test readability scores
    # Test technical correctness
    # Test consistency validation

def test_multi_format_export():
    """Test multiple format support."""
    # Test HTML export
    # Test PDF generation
    # Test Markdown output
    # Test interactive documentation
    # Test mobile-responsive formats
```

3. **Knowledge Base Tests** (`tests/test_knowledge_base.py`):
```python
def test_search_capabilities():
    """Test knowledge base search functionality."""
    # Test semantic search accuracy
    # Test search response time <2s
    # Test faceted search
    # Test auto-suggestions
    # Test search result ranking

def test_content_management():
    """Test content lifecycle management."""
    # Test content creation workflows
    # Test review and approval processes
    # Test version control
    # Test content expiration
    # Test duplicate detection

def test_analytics_and_insights():
    """Test usage analytics and insights."""
    # Test search analytics
    # Test content performance metrics
    # Test user behavior tracking
    # Test gap analysis
    # Test improvement recommendations
```

## Implementation Details

1. **Support Platform Core** (`app/support/support_platform.py`):
```python
from typing import Dict, Any, List, Optional, Set, Union
from dataclasses import dataclass, field
from enum import Enum
from datetime import datetime, timedelta
import asyncio
import json
import uuid
from collections import defaultdict, deque
from abc import ABC, abstractmethod
import logging

class TicketPriority(Enum):
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"
    URGENT = "urgent"

class TicketStatus(Enum):
    NEW = "new"
    ASSIGNED = "assigned"
    IN_PROGRESS = "in_progress"
    PENDING_CUSTOMER = "pending_customer"
    RESOLVED = "resolved"
    CLOSED = "closed"

class QueryType(Enum):
    TECHNICAL = "technical"
    BILLING = "billing"
    FEATURE_REQUEST = "feature_request"
    BUG_REPORT = "bug_report"
    GENERAL = "general"
    INTEGRATION = "integration"

@dataclass
class SupportTicket:
    ticket_id: str
    subject: str
    description: str
    priority: TicketPriority
    status: TicketStatus
    query_type: QueryType
    user_id: str
    assigned_agent: Optional[str]
    created_at: datetime
    updated_at: datetime
    resolution: Optional[str] = None
    satisfaction_score: Optional[float] = None
    tags: Set[str] = field(default_factory=set)
    attachments: List[Dict[str, Any]] = field(default_factory=list)

@dataclass
class KnowledgeArticle:
    article_id: str
    title: str
    content: str
    category: str
    tags: Set[str]
    author: str
    created_at: datetime
    updated_at: datetime
    version: int = 1
    status: str = "published"  # draft, review, published, archived
    view_count: int = 0
    helpful_votes: int = 0
    not_helpful_votes: int = 0

@dataclass
class UserQuery:
    query_id: str
    user_id: str
    query_text: str
    query_type: QueryType
    context: Dict[str, Any]
    timestamp: datetime
    resolved: bool = False
    resolution_method: Optional[str] = None  # ai, knowledge_base, human
    satisfaction_score: Optional[float] = None

@dataclass
class ConversationSession:
    session_id: str
    user_id: str
    started_at: datetime
    last_activity: datetime
    messages: List[Dict[str, Any]]
    context: Dict[str, Any]
    status: str = "active"  # active, escalated, resolved

class SupportPlatform:
    def __init__(self):
        self.tickets: Dict[str, SupportTicket] = {}
        self.knowledge_articles: Dict[str, KnowledgeArticle] = {}
        self.user_queries: Dict[str, UserQuery] = {}
        self.conversation_sessions: Dict[str, ConversationSession] = {}
        
        # AI and NLP components
        self.query_classifier = QueryClassifier()
        self.answer_generator = AnswerGenerator()
        self.intent_recognizer = IntentRecognizer()
        self.knowledge_search = KnowledgeSearch()
        
        # Documentation components
        self.doc_generator = DocumentationGenerator()
        self.content_analyzer = ContentAnalyzer()
        self.doc_templates: Dict[str, Dict[str, Any]] = {}
        
        # Analytics and metrics
        self.support_metrics = {
            "total_queries": 0,
            "ai_resolved_queries": 0,
            "human_escalations": 0,
            "average_resolution_time": 0.0,
            "user_satisfaction_score": 0.0,
            "knowledge_base_hits": 0
        }
        
        # Configuration
        self.config = {
            "ai_confidence_threshold": 0.8,
            "escalation_timeout": 1800,  # 30 minutes
            "max_conversation_length": 50,
            "auto_close_resolved_tickets": True,
            "satisfaction_survey_delay": 3600  # 1 hour
        }
        
        # Initialize platform
        asyncio.create_task(self._initialize_platform())
        
    async def _initialize_platform(self):
        """Initialize support platform components."""
        # Initialize AI components
        await self._initialize_ai_components()
        
        # Load knowledge base
        await self._load_knowledge_base()
        
        # Initialize documentation templates
        await self._initialize_doc_templates()
        
        # Start background tasks
        asyncio.create_task(self._monitor_ticket_sla())
        asyncio.create_task(self._update_knowledge_analytics())
        asyncio.create_task(self._generate_support_insights())
        asyncio.create_task(self._cleanup_old_sessions())
        
    async def handle_user_query(self, query_data: Dict[str, Any]) -> Dict[str, Any]:
        """Handle incoming user query with AI assistance."""
        query_id = str(uuid.uuid4())
        
        query = UserQuery(
            query_id=query_id,
            user_id=query_data.get("user_id", ""),
            query_text=query_data.get("query", ""),
            query_type=QueryType.GENERAL,  # Will be classified
            context=query_data.get("context", {}),
            timestamp=datetime.utcnow()
        )
        
        try:
            # Classify query type and intent
            classification = await self.query_classifier.classify_query(query.query_text, query.context)
            query.query_type = QueryType(classification.get("type", "general"))
            
            # Check for immediate AI resolution
            ai_response = await self._attempt_ai_resolution(query, classification)
            
            if ai_response.get("confidence", 0) >= self.config["ai_confidence_threshold"]:
                # AI can handle this query
                query.resolved = True
                query.resolution_method = "ai"
                
                self.support_metrics["ai_resolved_queries"] += 1
                
                response = {
                    "query_id": query_id,
                    "response": ai_response["answer"],
                    "confidence": ai_response["confidence"],
                    "resolution_method": "ai",
                    "suggested_articles": ai_response.get("related_articles", []),
                    "escalation_available": True
                }
            else:
                # Search knowledge base
                kb_results = await self.knowledge_search.search(
                    query.query_text, 
                    category=classification.get("category"),
                    limit=5
                )
                
                if kb_results and kb_results[0].get("relevance_score", 0) > 0.7:
                    # Knowledge base has good answer
                    query.resolved = True
                    query.resolution_method = "knowledge_base"
                    
                    self.support_metrics["knowledge_base_hits"] += 1
                    
                    response = {
                        "query_id": query_id,
                        "response": kb_results[0]["content"],
                        "resolution_method": "knowledge_base",
                        "article_id": kb_results[0]["article_id"],
                        "related_articles": kb_results[1:],
                        "escalation_available": True
                    }
                else:
                    # Escalate to human support
                    ticket = await self._create_support_ticket(query, classification)
                    
                    response = {
                        "query_id": query_id,
                        "resolution_method": "escalated",
                        "ticket_id": ticket.ticket_id,
                        "estimated_response_time": await self._estimate_response_time(ticket),
                        "alternative_resources": kb_results[:3] if kb_results else []
                    }
                    
            self.user_queries[query_id] = query
            self.support_metrics["total_queries"] += 1
            
            return response
            
        except Exception as e:
            logging.error(f"Query handling failed: {str(e)}")
            # Fallback to ticket creation
            ticket = await self._create_support_ticket(query, {"type": "general", "priority": "medium"})
            
            return {
                "query_id": query_id,
                "resolution_method": "escalated",
                "ticket_id": ticket.ticket_id,
                "error": "System error - query escalated to human support"
            }
            
    async def start_conversation(self, user_id: str, initial_message: str) -> ConversationSession:
        """Start interactive conversation session."""
        session_id = str(uuid.uuid4())
        
        session = ConversationSession(
            session_id=session_id,
            user_id=user_id,
            started_at=datetime.utcnow(),
            last_activity=datetime.utcnow(),
            messages=[
                {
                    "role": "user",
                    "content": initial_message,
                    "timestamp": datetime.utcnow().isoformat()
                }
            ],
            context={}
        )
        
        # Generate initial AI response
        ai_response = await self._generate_conversation_response(session)
        
        session.messages.append({
            "role": "assistant",
            "content": ai_response["content"],
            "confidence": ai_response.get("confidence", 0.0),
            "timestamp": datetime.utcnow().isoformat()
        })
        
        self.conversation_sessions[session_id] = session
        
        return session
        
    async def continue_conversation(self, session_id: str, message: str) -> Dict[str, Any]:
        """Continue existing conversation session."""
        if session_id not in self.conversation_sessions:
            raise ValueError(f"Conversation session {session_id} not found")
            
        session = self.conversation_sessions[session_id]
        
        # Add user message
        session.messages.append({
            "role": "user",
            "content": message,
            "timestamp": datetime.utcnow().isoformat()
        })
        
        session.last_activity = datetime.utcnow()
        
        # Check conversation length
        if len(session.messages) > self.config["max_conversation_length"]:
            # Escalate long conversations
            return await self._escalate_conversation(session)
            
        # Generate AI response
        ai_response = await self._generate_conversation_response(session)
        
        session.messages.append({
            "role": "assistant",
            "content": ai_response["content"],
            "confidence": ai_response.get("confidence", 0.0),
            "timestamp": datetime.utcnow().isoformat()
        })
        
        # Check if user seems frustrated or unsatisfied
        if await self._detect_user_frustration(session):
            return await self._escalate_conversation(session)
            
        return {
            "session_id": session_id,
            "response": ai_response["content"],
            "confidence": ai_response.get("confidence", 0.0),
            "escalation_available": True,
            "suggested_actions": ai_response.get("suggested_actions", [])
        }
        
    async def create_knowledge_article(self, article_data: Dict[str, Any]) -> KnowledgeArticle:
        """Create new knowledge base article."""
        article_id = str(uuid.uuid4())
        
        article = KnowledgeArticle(
            article_id=article_id,
            title=article_data.get("title", ""),
            content=article_data.get("content", ""),
            category=article_data.get("category", "general"),
            tags=set(article_data.get("tags", [])),
            author=article_data.get("author", "system"),
            created_at=datetime.utcnow(),
            updated_at=datetime.utcnow()
        )
        
        # Analyze content quality
        quality_analysis = await self.content_analyzer.analyze_article(article)
        
        if quality_analysis.get("quality_score", 0) < 0.7:
            article.status = "review"
            logging.warning(f"Article {article_id} requires review due to low quality score")
            
        self.knowledge_articles[article_id] = article
        
        # Update search index
        await self.knowledge_search.index_article(article)
        
        return article
        
    async def generate_documentation(self, doc_type: str, source_data: Dict[str, Any]) -> Dict[str, Any]:
        """Generate documentation automatically."""
        try:
            # Get appropriate template
            template = self.doc_templates.get(doc_type)
            if not template:
                raise ValueError(f"No template available for document type: {doc_type}")
                
            # Generate content
            generated_content = await self.doc_generator.generate_documentation(
                doc_type, source_data, template
            )
            
            # Analyze generated content
            content_analysis = await self.content_analyzer.analyze_content(generated_content)
            
            # Create knowledge article if quality is good
            if content_analysis.get("quality_score", 0) >= 0.8:
                article = await self.create_knowledge_article({
                    "title": generated_content.get("title", f"Auto-generated {doc_type}"),
                    "content": generated_content.get("content", ""),
                    "category": doc_type,
                    "tags": generated_content.get("tags", []),
                    "author": "auto_generator"
                })
                
                return {
                    "success": True,
                    "documentation": generated_content,
                    "quality_score": content_analysis["quality_score"],
                    "article_id": article.article_id,
                    "suggestions": content_analysis.get("improvement_suggestions", [])
                }
            else:
                return {
                    "success": True,
                    "documentation": generated_content,
                    "quality_score": content_analysis["quality_score"],
                    "requires_review": True,
                    "issues": content_analysis.get("issues", [])
                }
                
        except Exception as e:
            logging.error(f"Documentation generation failed: {str(e)}")
            raise
            
    async def get_support_analytics(self) -> Dict[str, Any]:
        """Get comprehensive support analytics."""
        # Calculate resolution metrics
        total_queries = self.support_metrics["total_queries"]
        ai_resolution_rate = (
            self.support_metrics["ai_resolved_queries"] / max(1, total_queries)
        ) * 100
        
        # Calculate ticket metrics
        open_tickets = len([t for t in self.tickets.values() if t.status not in [TicketStatus.RESOLVED, TicketStatus.CLOSED]])
        resolved_tickets = len([t for t in self.tickets.values() if t.status == TicketStatus.RESOLVED])
        
        # Calculate knowledge base metrics
        total_articles = len(self.knowledge_articles)
        published_articles = len([a for a in self.knowledge_articles.values() if a.status == "published"])
        
        # Calculate user satisfaction
        satisfaction_scores = [
            q.satisfaction_score for q in self.user_queries.values() 
            if q.satisfaction_score is not None
        ]
        avg_satisfaction = sum(satisfaction_scores) / len(satisfaction_scores) if satisfaction_scores else 0
        
        return {
            "query_resolution": {
                "total_queries": total_queries,
                "ai_resolution_rate": ai_resolution_rate,
                "knowledge_base_hit_rate": (self.support_metrics["knowledge_base_hits"] / max(1, total_queries)) * 100,
                "escalation_rate": (self.support_metrics["human_escalations"] / max(1, total_queries)) * 100
            },
            "ticket_metrics": {
                "open_tickets": open_tickets,
                "resolved_tickets": resolved_tickets,
                "average_resolution_time": self.support_metrics["average_resolution_time"],
                "tickets_by_priority": {
                    priority.value: len([t for t in self.tickets.values() if t.priority == priority])
                    for priority in TicketPriority
                }
            },
            "knowledge_base": {
                "total_articles": total_articles,
                "published_articles": published_articles,
                "total_views": sum(a.view_count for a in self.knowledge_articles.values()),
                "most_helpful_articles": await self._get_most_helpful_articles(5)
            },
            "user_satisfaction": {
                "average_score": avg_satisfaction,
                "total_responses": len(satisfaction_scores),
                "satisfaction_distribution": await self._calculate_satisfaction_distribution(satisfaction_scores)
            },
            "conversation_metrics": {
                "active_sessions": len([s for s in self.conversation_sessions.values() if s.status == "active"]),
                "escalated_sessions": len([s for s in self.conversation_sessions.values() if s.status == "escalated"]),
                "average_session_length": await self._calculate_average_session_length()
            }
        }
        
    async def _attempt_ai_resolution(self, query: UserQuery, classification: Dict[str, Any]) -> Dict[str, Any]:
        """Attempt to resolve query using AI."""
        # Generate answer using AI
        ai_answer = await self.answer_generator.generate_answer(
            query.query_text,
            classification,
            query.context
        )
        
        # Search for supporting articles
        related_articles = await self.knowledge_search.search(
            query.query_text,
            limit=3
        )
        
        return {
            "answer": ai_answer.get("content", ""),
            "confidence": ai_answer.get("confidence", 0.0),
            "reasoning": ai_answer.get("reasoning", ""),
            "related_articles": [
                {
                    "article_id": article["article_id"],
                    "title": article["title"],
                    "relevance": article["relevance_score"]
                }
                for article in related_articles
            ]
        }
        
    async def _create_support_ticket(self, query: UserQuery, classification: Dict[str, Any]) -> SupportTicket:
        """Create support ticket from user query."""
        ticket_id = str(uuid.uuid4())
        
        # Determine priority based on classification
        priority_mapping = {
            "billing": TicketPriority.HIGH,
            "bug_report": TicketPriority.HIGH,
            "technical": TicketPriority.MEDIUM,
            "feature_request": TicketPriority.LOW,
            "general": TicketPriority.LOW
        }
        
        priority = priority_mapping.get(classification.get("type", "general"), TicketPriority.MEDIUM)
        
        ticket = SupportTicket(
            ticket_id=ticket_id,
            subject=await self._generate_ticket_subject(query.query_text),
            description=query.query_text,
            priority=priority,
            status=TicketStatus.NEW,
            query_type=query.query_type,
            user_id=query.user_id,
            assigned_agent=None,
            created_at=datetime.utcnow(),
            updated_at=datetime.utcnow(),
            tags=set(classification.get("tags", []))
        )
        
        self.tickets[ticket_id] = ticket
        self.support_metrics["human_escalations"] += 1
        
        # Auto-assign based on type and availability
        await self._auto_assign_ticket(ticket)
        
        return ticket
```

2. **AI Components** (`app/support/ai_components.py`):
```python
from typing import Dict, Any, List, Optional
import asyncio
from abc import ABC, abstractmethod
import logging
from datetime import datetime

class QueryClassifier:
    def __init__(self):
        self.classification_models = {}
        self.intent_patterns = {
            "billing": ["billing", "payment", "invoice", "subscription", "charge"],
            "technical": ["error", "bug", "issue", "problem", "not working"],
            "feature_request": ["feature", "enhancement", "suggestion", "add", "improve"],
            "integration": ["api", "integration", "connect", "webhook", "sync"],
            "general": ["help", "support", "question", "how to", "guide"]
        }
        
    async def classify_query(self, query_text: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """Classify user query into type and intent."""
        query_lower = query_text.lower()
        
        # Simple pattern-based classification
        scores = {}
        for category, patterns in self.intent_patterns.items():
            score = sum(1 for pattern in patterns if pattern in query_lower)
            scores[category] = score
            
        # Get highest scoring category
        best_category = max(scores, key=scores.get) if scores else "general"
        confidence = scores[best_category] / max(1, len(query_text.split()))
        
        # Extract entities
        entities = await self._extract_entities(query_text)
        
        # Determine priority based on keywords
        priority = "medium"
        if any(word in query_lower for word in ["urgent", "critical", "broken", "down"]):
            priority = "high"
        elif any(word in query_lower for word in ["question", "curious", "wondering"]):
            priority = "low"
            
        return {
            "type": best_category,
            "confidence": confidence,
            "priority": priority,
            "entities": entities,
            "sentiment": await self._analyze_sentiment(query_text),
            "tags": await self._generate_tags(query_text, best_category)
        }
        
    async def _extract_entities(self, text: str) -> List[Dict[str, Any]]:
        """Extract named entities from text."""
        # Simplified entity extraction
        entities = []
        
        # Look for common entities
        words = text.split()
        for i, word in enumerate(words):
            if word.lower() in ["api", "endpoint", "database", "server"]:
                entities.append({
                    "type": "technical_component",
                    "value": word,
                    "position": i
                })
            elif word.startswith("$") and len(word) > 1:
                entities.append({
                    "type": "monetary_amount",
                    "value": word,
                    "position": i
                })
                
        return entities
        
    async def _analyze_sentiment(self, text: str) -> Dict[str, Any]:
        """Analyze sentiment of query text."""
        # Simplified sentiment analysis
        positive_words = ["good", "great", "excellent", "love", "happy", "satisfied"]
        negative_words = ["bad", "terrible", "awful", "hate", "angry", "frustrated", "problem", "issue", "broken"]
        
        text_lower = text.lower()
        positive_count = sum(1 for word in positive_words if word in text_lower)
        negative_count = sum(1 for word in negative_words if word in text_lower)
        
        if negative_count > positive_count:
            sentiment = "negative"
            score = -0.5 - (negative_count - positive_count) * 0.1
        elif positive_count > negative_count:
            sentiment = "positive"
            score = 0.5 + (positive_count - negative_count) * 0.1
        else:
            sentiment = "neutral"
            score = 0.0
            
        return {
            "sentiment": sentiment,
            "score": max(-1.0, min(1.0, score)),
            "confidence": abs(score)
        }

class AnswerGenerator:
    def __init__(self):
        self.knowledge_base = {}
        self.answer_templates = {
            "billing": "For billing inquiries, please check your account dashboard. If you need specific assistance with {entity}, please contact our billing team.",
            "technical": "Based on your description of {issue}, here are some troubleshooting steps: {steps}",
            "feature_request": "Thank you for your feature suggestion regarding {feature}. We'll add this to our product roadmap for evaluation.",
            "integration": "For {integration_type} integration, please refer to our API documentation at {docs_link}. Here's a quick example: {example}",
            "general": "I'd be happy to help you with {topic}. Here's what I found: {information}"
        }
        
    async def generate_answer(self, query: str, classification: Dict[str, Any], 
                            context: Dict[str, Any]) -> Dict[str, Any]:
        """Generate AI answer for user query."""
        query_type = classification.get("type", "general")
        entities = classification.get("entities", [])
        
        # Get base template
        template = self.answer_templates.get(query_type, self.answer_templates["general"])
        
        # Fill template with context
        answer_content = await self._fill_template(template, query, entities, context)
        
        # Calculate confidence based on various factors
        confidence = await self._calculate_answer_confidence(query, classification, context)
        
        # Generate reasoning
        reasoning = await self._generate_reasoning(query, classification, answer_content)
        
        return {
            "content": answer_content,
            "confidence": confidence,
            "reasoning": reasoning,
            "sources": await self._get_answer_sources(query, query_type),
            "follow_up_questions": await self._generate_follow_up_questions(query, query_type)
        }
        
    async def _fill_template(self, template: str, query: str, entities: List[Dict[str, Any]], 
                           context: Dict[str, Any]) -> str:
        """Fill answer template with relevant information."""
        # Extract key information from query and entities
        filled_template = template
        
        # Replace common placeholders
        if "{entity}" in template and entities:
            entity_value = entities[0].get("value", "the item")
            filled_template = filled_template.replace("{entity}", entity_value)
            
        if "{issue}" in template:
            # Extract the main issue from query
            issue = query if len(query) < 50 else query[:50] + "..."
            filled_template = filled_template.replace("{issue}", issue)
            
        if "{steps}" in template:
            # Provide generic troubleshooting steps
            steps = "1. Check your internet connection\n2. Refresh the page\n3. Clear your browser cache\n4. Try again in a few minutes"
            filled_template = filled_template.replace("{steps}", steps)
            
        if "{docs_link}" in template:
            filled_template = filled_template.replace("{docs_link}", "https://docs.mobius.ai/api")
            
        return filled_template
        
    async def _calculate_answer_confidence(self, query: str, classification: Dict[str, Any], 
                                         context: Dict[str, Any]) -> float:
        """Calculate confidence score for generated answer."""
        base_confidence = 0.5
        
        # Boost confidence for well-classified queries
        classification_confidence = classification.get("confidence", 0.0)
        base_confidence += classification_confidence * 0.3
        
        # Boost confidence for queries with clear entities
        if classification.get("entities"):
            base_confidence += 0.1
            
        # Reduce confidence for negative sentiment (frustrated users)
        sentiment = classification.get("sentiment", {})
        if sentiment.get("sentiment") == "negative":
            base_confidence -= 0.2
            
        # Boost confidence for common query types
        common_types = ["billing", "general"]
        if classification.get("type") in common_types:
            base_confidence += 0.1
            
        return max(0.0, min(1.0, base_confidence))

class KnowledgeSearch:
    def __init__(self):
        self.search_index = {}
        self.article_embeddings = {}
        
    async def search(self, query: str, category: str = None, limit: int = 10) -> List[Dict[str, Any]]:
        """Search knowledge base for relevant articles."""
        # Simplified search implementation
        results = []
        
        query_lower = query.lower()
        query_words = set(query_lower.split())
        
        for article_id, article in self.search_index.items():
            # Skip if category filter doesn't match
            if category and article.get("category") != category:
                continue
                
            # Calculate relevance score
            content_words = set(article.get("content", "").lower().split())
            title_words = set(article.get("title", "").lower().split())
            
            # Word overlap score
            content_overlap = len(query_words.intersection(content_words)) / len(query_words)
            title_overlap = len(query_words.intersection(title_words)) / len(query_words)
            
            # Weight title matches more heavily
            relevance_score = (content_overlap * 0.7) + (title_overlap * 0.3)
            
            # Boost score for popular articles
            popularity_boost = min(0.1, article.get("view_count", 0) / 1000)
            relevance_score += popularity_boost
            
            if relevance_score > 0.1:  # Minimum relevance threshold
                results.append({
                    "article_id": article_id,
                    "title": article.get("title", ""),
                    "content": article.get("content", "")[:500] + "..." if len(article.get("content", "")) > 500 else article.get("content", ""),
                    "category": article.get("category", ""),
                    "relevance_score": relevance_score,
                    "view_count": article.get("view_count", 0)
                })
                
        # Sort by relevance score
        results.sort(key=lambda x: x["relevance_score"], reverse=True)
        
        return results[:limit]
        
    async def index_article(self, article: 'KnowledgeArticle'):
        """Add article to search index."""
        self.search_index[article.article_id] = {
            "title": article.title,
            "content": article.content,
            "category": article.category,
            "tags": list(article.tags),
            "view_count": article.view_count,
            "created_at": article.created_at.isoformat()
        }

class DocumentationGenerator:
    def __init__(self):
        self.generators = {
            "api_docs": self._generate_api_documentation,
            "user_guide": self._generate_user_guide,
            "troubleshooting": self._generate_troubleshooting_guide,
            "integration_guide": self._generate_integration_guide,
            "release_notes": self._generate_release_notes
        }
        
    async def generate_documentation(self, doc_type: str, source_data: Dict[str, Any], 
                                   template: Dict[str, Any]) -> Dict[str, Any]:
        """Generate documentation of specified type."""
        generator = self.generators.get(doc_type)
        if not generator:
            raise ValueError(f"No generator available for {doc_type}")
            
        return await generator(source_data, template)
        
    async def _generate_api_documentation(self, source_data: Dict[str, Any], 
                                        template: Dict[str, Any]) -> Dict[str, Any]:
        """Generate API documentation from source code."""
        # Extract API endpoints and methods
        endpoints = source_data.get("endpoints", [])
        
        doc_content = "# API Documentation\n\n"
        doc_content += "This document describes the available API endpoints.\n\n"
        
        for endpoint in endpoints:
            doc_content += f"## {endpoint.get('method', 'GET')} {endpoint.get('path', '')}\n\n"
            doc_content += f"{endpoint.get('description', 'No description available.')}\n\n"
            
            # Parameters
            if endpoint.get("parameters"):
                doc_content += "### Parameters\n\n"
                for param in endpoint["parameters"]:
                    doc_content += f"- `{param.get('name')}` ({param.get('type', 'string')}): {param.get('description', 'No description')}\n"
                doc_content += "\n"
                
            # Example
            if endpoint.get("example"):
                doc_content += "### Example\n\n"
                doc_content += f"```json\n{endpoint['example']}\n```\n\n"
                
        return {
            "title": "API Documentation",
            "content": doc_content,
            "format": "markdown",
            "tags": ["api", "documentation", "reference"],
            "generated_at": datetime.utcnow().isoformat()
        }
        
    async def _generate_user_guide(self, source_data: Dict[str, Any], 
                                 template: Dict[str, Any]) -> Dict[str, Any]:
        """Generate user guide documentation."""
        features = source_data.get("features", [])
        
        doc_content = "# User Guide\n\n"
        doc_content += "This guide will help you get started with the platform.\n\n"
        
        doc_content += "## Getting Started\n\n"
        doc_content += "1. Create an account\n"
        doc_content += "2. Set up your workspace\n"
        doc_content += "3. Invite team members\n\n"
        
        for feature in features:
            doc_content += f"## {feature.get('name', 'Feature')}\n\n"
            doc_content += f"{feature.get('description', 'No description available.')}\n\n"
            
            if feature.get("steps"):
                doc_content += "### How to use:\n\n"
                for i, step in enumerate(feature["steps"], 1):
                    doc_content += f"{i}. {step}\n"
                doc_content += "\n"
                
        return {
            "title": "User Guide",
            "content": doc_content,
            "format": "markdown",
            "tags": ["user", "guide", "tutorial"],
            "generated_at": datetime.utcnow().isoformat()
        }
```

3. **Support Analytics** (`app/support/analytics.py`):
```python
from typing import Dict, Any, List, Optional
import asyncio
from datetime import datetime, timedelta
from collections import defaultdict
import logging

class SupportAnalytics:
    def __init__(self, support_platform):
        self.platform = support_platform
        self.analytics_cache = {}
        self.cache_ttl = 300  # 5 minutes
        
    async def generate_support_insights(self) -> Dict[str, Any]:
        """Generate comprehensive support insights."""
        insights = {
            "query_patterns": await self._analyze_query_patterns(),
            "resolution_trends": await self._analyze_resolution_trends(),
            "knowledge_gaps": await self._identify_knowledge_gaps(),
            "agent_performance": await self._analyze_agent_performance(),
            "user_satisfaction_trends": await self._analyze_satisfaction_trends(),
            "recommendations": await self._generate_recommendations()
        }
        
        return insights
        
    async def _analyze_query_patterns(self) -> Dict[str, Any]:
        """Analyze patterns in user queries."""
        queries = list(self.platform.user_queries.values())
        
        # Group by query type
        type_counts = defaultdict(int)
        for query in queries:
            type_counts[query.query_type.value] += 1
            
        # Analyze timing patterns
        hourly_distribution = defaultdict(int)
        for query in queries:
            hour = query.timestamp.hour
            hourly_distribution[hour] += 1
            
        # Identify trending topics
        trending_topics = await self._identify_trending_topics(queries)
        
        return {
            "query_types": dict(type_counts),
            "hourly_distribution": dict(hourly_distribution),
            "trending_topics": trending_topics,
            "total_queries": len(queries),
            "peak_hour": max(hourly_distribution, key=hourly_distribution.get) if hourly_distribution else 0
        }
        
    async def _identify_knowledge_gaps(self) -> List[Dict[str, Any]]:
        """Identify gaps in knowledge base."""
        # Find queries that couldn't be resolved by AI or knowledge base
        unresolved_queries = [
            q for q in self.platform.user_queries.values()
            if not q.resolved or q.resolution_method == "escalated"
        ]
        
        # Group similar unresolved queries
        topic_groups = defaultdict(list)
        for query in unresolved_queries:
            # Simple topic grouping by keywords
            words = query.query_text.lower().split()
            key_topics = [word for word in words if len(word) > 4]  # Filter short words
            
            if key_topics:
                topic_key = "_".join(sorted(key_topics[:3]))  # Use top 3 topics
                topic_groups[topic_key].append(query)
                
        # Identify significant gaps
        gaps = []
        for topic, queries in topic_groups.items():
            if len(queries) >= 3:  # Multiple similar unresolved queries
                gaps.append({
                    "topic": topic.replace("_", " "),
                    "query_count": len(queries),
                    "sample_queries": [q.query_text for q in queries[:3]],
                    "priority": "high" if len(queries) > 10 else "medium"
                })
                
        return sorted(gaps, key=lambda x: x["query_count"], reverse=True)
        
    async def _generate_recommendations(self) -> List[Dict[str, Any]]:
        """Generate actionable recommendations."""
        recommendations = []
        
        # Analyze AI resolution rate
        total_queries = self.platform.support_metrics["total_queries"]
        ai_resolved = self.platform.support_metrics["ai_resolved_queries"]
        ai_rate = (ai_resolved / max(1, total_queries)) * 100
        
        if ai_rate < 60:
            recommendations.append({
                "type": "improvement",
                "priority": "high",
                "title": "Improve AI Resolution Rate",
                "description": f"Current AI resolution rate is {ai_rate:.1f}%. Consider improving answer quality and expanding knowledge base.",
                "actions": [
                    "Review frequently escalated queries",
                    "Enhance AI training data",
                    "Create more comprehensive knowledge articles"
                ]
            })
            
        # Check for knowledge gaps
        gaps = await self._identify_knowledge_gaps()
        if len(gaps) > 3:
            recommendations.append({
                "type": "content",
                "priority": "medium",
                "title": "Address Knowledge Gaps",
                "description": f"Found {len(gaps)} significant knowledge gaps that could be addressed with new articles.",
                "actions": [
                    f"Create articles for: {', '.join([gap['topic'] for gap in gaps[:3]])}",
                    "Review and update existing documentation",
                    "Implement user feedback collection"
                ]
            })
            
        return recommendations
```

## Dependencies
- Task 040: Advanced Security Framework
- Task 044: Advanced Analytics and Business Intelligence Platform
- Task 008: Async Database Operations
- Natural language processing libraries (spaCy, NLTK)
- Machine learning frameworks for AI components
- Search engines (Elasticsearch, OpenSearch)
- Document generation libraries (Pandoc, WeasyPrint)

## Estimated Time
26-30 hours

## Required Skills
- Natural language processing and AI/ML
- Knowledge management systems
- Conversational AI and chatbot development
- Documentation automation and generation
- Search and information retrieval
- Customer support workflow design
- Analytics and business intelligence