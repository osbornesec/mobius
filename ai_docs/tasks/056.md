# Task 056: Enterprise SLA and Monitoring System

## Overview
Implement a comprehensive enterprise-grade Service Level Agreement (SLA) and monitoring system that provides real-time performance tracking, automated alerting, SLA compliance reporting, and proactive issue detection. This system will ensure 99.9% uptime guarantees, monitor critical performance metrics, and provide enterprise customers with detailed service level reporting and compliance dashboards.

## Success Criteria
- [ ] SLA monitoring achieves 99.9% uptime measurement accuracy with <5 second detection latency
- [ ] Automated alerting system provides multi-channel notifications with escalation policies
- [ ] SLA compliance reporting generates accurate monthly/quarterly reports with 100% data integrity
- [ ] Performance monitoring tracks 50+ key metrics with real-time alerting thresholds
- [ ] Enterprise dashboard provides real-time SLA status with 5-second update frequency
- [ ] Incident management system coordinates response across teams with automated workflows

## Test First Approach

### Tests to Write BEFORE Implementation:

1. **SLA Monitoring Tests** (`tests/backend/unit/test_sla_monitoring.py`):
```python
def test_uptime_monitoring():
    """Test uptime monitoring and calculation accuracy."""
    # Test service availability detection
    # Test uptime percentage calculation
    # Test downtime event recording
    # Test SLA threshold compliance checking
    # Test historical uptime data aggregation

def test_performance_monitoring():
    """Test performance metrics monitoring and alerting."""
    # Test response time monitoring
    # Test throughput monitoring
    # Test error rate calculation
    # Test performance threshold violations
    # Test performance trend analysis

def test_sla_compliance_tracking():
    """Test SLA compliance tracking and reporting."""
    # Test SLA metric collection accuracy
    # Test compliance percentage calculation
    # Test SLA breach detection
    # Test compliance trend tracking
    # Test automated compliance reporting
```

2. **Alerting System Tests** (`tests/backend/unit/test_alerting_system.py`):
```python
def test_alert_generation():
    """Test alert generation for SLA violations."""
    # Test threshold-based alert generation
    # Test alert severity classification
    # Test alert deduplication
    # Test alert correlation
    # Test alert lifecycle management

def test_notification_delivery():
    """Test multi-channel notification delivery."""
    # Test email notification delivery
    # Test Slack notification delivery
    # Test PagerDuty integration
    # Test SMS notification delivery
    # Test webhook notification delivery

def test_escalation_policies():
    """Test alert escalation and workflow automation."""
    # Test escalation timer accuracy
    # Test escalation policy execution
    # Test on-call rotation handling
    # Test escalation acknowledgment
    # Test automatic escalation cancellation
```

3. **SLA Reporting Tests** (`tests/backend/unit/test_sla_reporting.py`):
```python
def test_sla_report_generation():
    """Test SLA report generation and accuracy."""
    # Test monthly SLA report generation
    # Test quarterly SLA report generation
    # Test custom date range reporting
    # Test report data accuracy
    # Test report formatting and presentation

def test_compliance_metrics():
    """Test SLA compliance metric calculations."""
    # Test uptime percentage calculation
    # Test availability calculation
    # Test performance metric aggregation
    # Test SLA credit calculation
    # Test compliance trend analysis

def test_dashboard_data():
    """Test real-time dashboard data accuracy."""
    # Test real-time metric updates
    # Test dashboard data consistency
    # Test historical data visualization
    # Test alert status display
    # Test performance chart accuracy
```

## Implementation Details

### 1. SLA Monitoring Core System (`app/sla_monitoring/monitor.py`):
```python
import asyncio
import time
import logging
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from enum import Enum
import aioredis
import asyncpg
import httpx
from prometheus_client import Gauge, Counter, Histogram, start_http_server
import json

class ServiceStatus(Enum):
    """Service status enumeration."""
    UP = "up"
    DOWN = "down"
    DEGRADED = "degraded"
    UNKNOWN = "unknown"

class AlertSeverity(Enum):
    """Alert severity levels."""
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    INFO = "info"

@dataclass
class SLAMetric:
    """SLA metric definition."""
    name: str
    description: str
    target_value: float
    threshold_warning: float
    threshold_critical: float
    unit: str
    calculation_method: str  # "average", "percentile", "count", "ratio"
    measurement_window: int  # seconds
    organization_id: Optional[str] = None

@dataclass
class ServiceCheck:
    """Service health check definition."""
    service_name: str
    check_type: str  # "http", "tcp", "database", "custom"
    endpoint: Optional[str]
    expected_response: Optional[str]
    timeout_seconds: int
    check_interval: int
    organization_id: Optional[str] = None

@dataclass
class SLAViolation:
    """SLA violation record."""
    id: str
    metric_name: str
    service_name: str
    violation_type: str
    severity: AlertSeverity
    threshold_value: float
    actual_value: float
    started_at: datetime
    ended_at: Optional[datetime]
    organization_id: str

class EnterpriseSLAMonitor:
    """Enterprise SLA monitoring and compliance system."""

    def __init__(self, postgres_url: str, redis_url: str, prometheus_port: int = 8000):
        self.postgres_url = postgres_url
        self.redis_url = redis_url
        self.prometheus_port = prometheus_port
        self.postgres_pool = None
        self.redis_pool = None

        # Service monitoring state
        self.service_checks: Dict[str, ServiceCheck] = {}
        self.sla_metrics: Dict[str, SLAMetric] = {}
        self.active_violations: Dict[str, SLAViolation] = {}
        self.service_statuses: Dict[str, ServiceStatus] = {}

        # Prometheus metrics
        self.setup_prometheus_metrics()

        # Performance tracking
        self.performance_data: Dict[str, List[float]] = {}

    def setup_prometheus_metrics(self):
        """Setup Prometheus metrics for monitoring."""
        self.uptime_gauge = Gauge(
            'service_uptime_ratio',
            'Service uptime ratio',
            ['service', 'organization']
        )

        self.response_time_histogram = Histogram(
            'service_response_time_seconds',
            'Service response time in seconds',
            ['service', 'organization']
        )

        self.error_rate_gauge = Gauge(
            'service_error_rate',
            'Service error rate percentage',
            ['service', 'organization']
        )

        self.sla_compliance_gauge = Gauge(
            'sla_compliance_ratio',
            'SLA compliance ratio',
            ['metric', 'organization']
        )

        self.alert_counter = Counter(
            'alerts_total',
            'Total number of alerts generated',
            ['severity', 'service', 'organization']
        )

    async def initialize(self):
        """Initialize SLA monitoring system."""
        try:
            # Initialize database connections
            self.postgres_pool = await asyncpg.create_pool(
                self.postgres_url,
                min_size=5,
                max_size=15
            )

            self.redis_pool = aioredis.ConnectionPool.from_url(
                self.redis_url, max_connections=15
            )

            # Create database tables
            await self._create_monitoring_tables()

            # Load configuration
            await self._load_monitoring_configuration()

            # Start Prometheus metrics server
            start_http_server(self.prometheus_port)

            # Start background monitoring tasks
            asyncio.create_task(self._run_service_checks())
            asyncio.create_task(self._calculate_sla_metrics())
            asyncio.create_task(self._process_violations())
            asyncio.create_task(self._cleanup_old_data())

            logging.info("Enterprise SLA Monitor initialized successfully")

        except Exception as e:
            logging.error(f"Failed to initialize SLA monitor: {e}")
            raise

    async def _create_monitoring_tables(self):
        """Create monitoring database tables."""
        try:
            async with self.postgres_pool.acquire() as conn:
                # Service checks table
                await conn.execute("""
                    CREATE TABLE IF NOT EXISTS service_checks (
                        id VARCHAR PRIMARY KEY,
                        service_name VARCHAR NOT NULL,
                        check_type VARCHAR NOT NULL,
                        endpoint VARCHAR,
                        expected_response VARCHAR,
                        timeout_seconds INTEGER NOT NULL,
                        check_interval INTEGER NOT NULL,
                        organization_id VARCHAR,
                        is_active BOOLEAN DEFAULT TRUE,
                        created_at TIMESTAMP DEFAULT NOW(),
                        updated_at TIMESTAMP DEFAULT NOW()
                    )
                """)

                # SLA metrics table
                await conn.execute("""
                    CREATE TABLE IF NOT EXISTS sla_metrics (
                        id VARCHAR PRIMARY KEY,
                        name VARCHAR NOT NULL,
                        description TEXT,
                        target_value DECIMAL NOT NULL,
                        threshold_warning DECIMAL NOT NULL,
                        threshold_critical DECIMAL NOT NULL,
                        unit VARCHAR NOT NULL,
                        calculation_method VARCHAR NOT NULL,
                        measurement_window INTEGER NOT NULL,
                        organization_id VARCHAR,
                        is_active BOOLEAN DEFAULT TRUE,
                        created_at TIMESTAMP DEFAULT NOW()
                    )
                """)

                # Service status history table
                await conn.execute("""
                    CREATE TABLE IF NOT EXISTS service_status_history (
                        id VARCHAR PRIMARY KEY,
                        service_name VARCHAR NOT NULL,
                        status VARCHAR NOT NULL,
                        response_time_ms DECIMAL,
                        error_message TEXT,
                        checked_at TIMESTAMP NOT NULL,
                        organization_id VARCHAR
                    )
                """)

                # SLA violations table
                await conn.execute("""
                    CREATE TABLE IF NOT EXISTS sla_violations (
                        id VARCHAR PRIMARY KEY,
                        metric_name VARCHAR NOT NULL,
                        service_name VARCHAR NOT NULL,
                        violation_type VARCHAR NOT NULL,
                        severity VARCHAR NOT NULL,
                        threshold_value DECIMAL NOT NULL,
                        actual_value DECIMAL NOT NULL,
                        started_at TIMESTAMP NOT NULL,
                        ended_at TIMESTAMP,
                        organization_id VARCHAR NOT NULL,
                        resolution_notes TEXT
                    )
                """)

                # SLA compliance reports table
                await conn.execute("""
                    CREATE TABLE IF NOT EXISTS sla_compliance_reports (
                        id VARCHAR PRIMARY KEY,
                        organization_id VARCHAR NOT NULL,
                        report_period VARCHAR NOT NULL,
                        period_start TIMESTAMP NOT NULL,
                        period_end TIMESTAMP NOT NULL,
                        metrics_data JSONB NOT NULL,
                        compliance_summary JSONB NOT NULL,
                        generated_at TIMESTAMP DEFAULT NOW()
                    )
                """)

                # Create indexes
                await conn.execute("""
                    CREATE INDEX IF NOT EXISTS idx_service_status_history_service_time
                    ON service_status_history(service_name, checked_at)
                """)

                await conn.execute("""
                    CREATE INDEX IF NOT EXISTS idx_sla_violations_org_time
                    ON sla_violations(organization_id, started_at)
                """)

        except Exception as e:
            logging.error(f"Error creating monitoring tables: {e}")
            raise

    async def _load_monitoring_configuration(self):
        """Load monitoring configuration from database."""
        try:
            async with self.postgres_pool.acquire() as conn:
                # Load service checks
                checks = await conn.fetch(
                    "SELECT * FROM service_checks WHERE is_active = TRUE"
                )

                for check in checks:
                    service_check = ServiceCheck(
                        service_name=check["service_name"],
                        check_type=check["check_type"],
                        endpoint=check["endpoint"],
                        expected_response=check["expected_response"],
                        timeout_seconds=check["timeout_seconds"],
                        check_interval=check["check_interval"],
                        organization_id=check["organization_id"]
                    )
                    self.service_checks[check["id"]] = service_check

                # Load SLA metrics
                metrics = await conn.fetch(
                    "SELECT * FROM sla_metrics WHERE is_active = TRUE"
                )

                for metric in metrics:
                    sla_metric = SLAMetric(
                        name=metric["name"],
                        description=metric["description"],
                        target_value=float(metric["target_value"]),
                        threshold_warning=float(metric["threshold_warning"]),
                        threshold_critical=float(metric["threshold_critical"]),
                        unit=metric["unit"],
                        calculation_method=metric["calculation_method"],
                        measurement_window=metric["measurement_window"],
                        organization_id=metric["organization_id"]
                    )
                    self.sla_metrics[metric["id"]] = sla_metric

        except Exception as e:
            logging.error(f"Error loading monitoring configuration: {e}")
            raise

    async def _run_service_checks(self):
        """Run continuous service health checks."""
        while True:
            try:
                check_tasks = []

                for check_id, service_check in self.service_checks.items():
                    check_tasks.append(
                        self._perform_service_check(check_id, service_check)
                    )

                if check_tasks:
                    await asyncio.gather(*check_tasks, return_exceptions=True)

                # Wait before next round of checks
                await asyncio.sleep(10)  # Check every 10 seconds

            except Exception as e:
                logging.error(f"Error in service checks: {e}")
                await asyncio.sleep(60)  # Wait longer on error

    async def _perform_service_check(self, check_id: str, service_check: ServiceCheck):
        """Perform individual service health check."""
        start_time = time.time()
        status = ServiceStatus.UNKNOWN
        error_message = None

        try:
            if service_check.check_type == "http":
                status = await self._perform_http_check(service_check)
            elif service_check.check_type == "tcp":
                status = await self._perform_tcp_check(service_check)
            elif service_check.check_type == "database":
                status = await self._perform_database_check(service_check)
            else:
                status = ServiceStatus.UNKNOWN
                error_message = f"Unknown check type: {service_check.check_type}"

        except Exception as e:
            status = ServiceStatus.DOWN
            error_message = str(e)

        response_time_ms = (time.time() - start_time) * 1000

        # Record status
        await self._record_service_status(
            service_check.service_name,
            status,
            response_time_ms,
            error_message,
            service_check.organization_id
        )

        # Update Prometheus metrics
        self._update_prometheus_metrics(
            service_check.service_name,
            status,
            response_time_ms,
            service_check.organization_id
        )

    async def _perform_http_check(self, service_check: ServiceCheck) -> ServiceStatus:
        """Perform HTTP health check."""
        try:
            async with httpx.AsyncClient() as client:
                response = await client.get(
                    service_check.endpoint,
                    timeout=service_check.timeout_seconds
                )

                if response.status_code == 200:
                    if service_check.expected_response:
                        if service_check.expected_response in response.text:
                            return ServiceStatus.UP
                        else:
                            return ServiceStatus.DEGRADED
                    return ServiceStatus.UP
                elif 400 <= response.status_code < 500:
                    return ServiceStatus.DEGRADED
                else:
                    return ServiceStatus.DOWN

        except Exception:
            return ServiceStatus.DOWN

    async def _perform_tcp_check(self, service_check: ServiceCheck) -> ServiceStatus:
        """Perform TCP connection check."""
        try:
            # Parse endpoint for host and port
            if ':' not in service_check.endpoint:
                return ServiceStatus.DOWN

            host, port = service_check.endpoint.rsplit(':', 1)
            port = int(port)

            # Attempt TCP connection
            future = asyncio.open_connection(host, port)
            reader, writer = await asyncio.wait_for(
                future,
                timeout=service_check.timeout_seconds
            )

            writer.close()
            await writer.wait_closed()

            return ServiceStatus.UP

        except Exception:
            return ServiceStatus.DOWN

    async def _perform_database_check(self, service_check: ServiceCheck) -> ServiceStatus:
        """Perform database connectivity check."""
        try:
            # Simple database connection test
            async with self.postgres_pool.acquire() as conn:
                await conn.fetchval("SELECT 1")
            return ServiceStatus.UP

        except Exception:
            return ServiceStatus.DOWN

    async def _record_service_status(
        self,
        service_name: str,
        status: ServiceStatus,
        response_time_ms: float,
        error_message: Optional[str],
        organization_id: Optional[str]
    ):
        """Record service status in database."""
        try:
            async with self.postgres_pool.acquire() as conn:
                await conn.execute(
                    """
                    INSERT INTO service_status_history
                    (id, service_name, status, response_time_ms, error_message,
                     checked_at, organization_id)
                    VALUES ($1, $2, $3, $4, $5, $6, $7)
                    """,
                    f"{service_name}_{int(time.time() * 1000)}",
                    service_name,
                    status.value,
                    response_time_ms,
                    error_message,
                    datetime.utcnow(),
                    organization_id
                )

            # Update current status
            self.service_statuses[service_name] = status

        except Exception as e:
            logging.error(f"Error recording service status: {e}")

    def _update_prometheus_metrics(
        self,
        service_name: str,
        status: ServiceStatus,
        response_time_ms: float,
        organization_id: Optional[str]
    ):
        """Update Prometheus metrics."""
        try:
            org_id = organization_id or "default"

            # Update response time
            self.response_time_histogram.labels(
                service=service_name,
                organization=org_id
            ).observe(response_time_ms / 1000)

            # Update uptime (1 for UP, 0 for DOWN/DEGRADED)
            uptime_value = 1.0 if status == ServiceStatus.UP else 0.0
            self.uptime_gauge.labels(
                service=service_name,
                organization=org_id
            ).set(uptime_value)

        except Exception as e:
            logging.error(f"Error updating Prometheus metrics: {e}")

    async def _calculate_sla_metrics(self):
        """Calculate SLA metrics and check compliance."""
        while True:
            try:
                for metric_id, sla_metric in self.sla_metrics.items():
                    await self._calculate_metric_compliance(metric_id, sla_metric)

                # Wait before next calculation
                await asyncio.sleep(60)  # Calculate every minute

            except Exception as e:
                logging.error(f"Error calculating SLA metrics: {e}")
                await asyncio.sleep(300)  # Wait longer on error

    async def _calculate_metric_compliance(self, metric_id: str, sla_metric: SLAMetric):
        """Calculate compliance for a specific SLA metric."""
        try:
            current_time = datetime.utcnow()
            window_start = current_time - timedelta(seconds=sla_metric.measurement_window)

            async with self.postgres_pool.acquire() as conn:
                if sla_metric.name == "uptime_percentage":
                    # Calculate uptime percentage
                    total_checks = await conn.fetchval(
                        """
                        SELECT COUNT(*) FROM service_status_history
                        WHERE checked_at BETWEEN $1 AND $2
                        AND ($3 IS NULL OR organization_id = $3)
                        """,
                        window_start, current_time, sla_metric.organization_id
                    )

                    up_checks = await conn.fetchval(
                        """
                        SELECT COUNT(*) FROM service_status_history
                        WHERE checked_at BETWEEN $1 AND $2
                        AND status = 'up'
                        AND ($3 IS NULL OR organization_id = $3)
                        """,
                        window_start, current_time, sla_metric.organization_id
                    )

                    if total_checks > 0:
                        uptime_percentage = (up_checks / total_checks) * 100
                        await self._check_sla_violation(
                            metric_id, sla_metric, uptime_percentage
                        )

                elif sla_metric.name == "response_time_p95":
                    # Calculate 95th percentile response time
                    response_times = await conn.fetch(
                        """
                        SELECT response_time_ms FROM service_status_history
                        WHERE checked_at BETWEEN $1 AND $2
                        AND response_time_ms IS NOT NULL
                        AND status = 'up'
                        AND ($3 IS NULL OR organization_id = $3)
                        ORDER BY response_time_ms
                        """,
                        window_start, current_time, sla_metric.organization_id
                    )

                    if response_times:
                        times = [float(row["response_time_ms"]) for row in response_times]
                        p95_index = int(len(times) * 0.95)
                        p95_response_time = times[p95_index] if p95_index < len(times) else times[-1]

                        await self._check_sla_violation(
                            metric_id, sla_metric, p95_response_time
                        )

                elif sla_metric.name == "error_rate_percentage":
                    # Calculate error rate percentage
                    total_requests = await conn.fetchval(
                        """
                        SELECT COUNT(*) FROM service_status_history
                        WHERE checked_at BETWEEN $1 AND $2
                        AND ($3 IS NULL OR organization_id = $3)
                        """,
                        window_start, current_time, sla_metric.organization_id
                    )

                    error_requests = await conn.fetchval(
                        """
                        SELECT COUNT(*) FROM service_status_history
                        WHERE checked_at BETWEEN $1 AND $2
                        AND status IN ('down', 'degraded')
                        AND ($3 IS NULL OR organization_id = $3)
                        """,
                        window_start, current_time, sla_metric.organization_id
                    )

                    if total_requests > 0:
                        error_rate = (error_requests / total_requests) * 100
                        await self._check_sla_violation(
                            metric_id, sla_metric, error_rate
                        )

        except Exception as e:
            logging.error(f"Error calculating metric compliance: {e}")

    async def _check_sla_violation(
        self,
        metric_id: str,
        sla_metric: SLAMetric,
        current_value: float
    ):
        """Check for SLA violations and create alerts."""
        try:
            violation_key = f"{metric_id}_{sla_metric.organization_id}"

            # Determine if there's a violation
            if sla_metric.name in ["uptime_percentage"] and current_value < sla_metric.threshold_critical:
                severity = AlertSeverity.CRITICAL
            elif sla_metric.name in ["uptime_percentage"] and current_value < sla_metric.threshold_warning:
                severity = AlertSeverity.HIGH
            elif sla_metric.name in ["response_time_p95", "error_rate_percentage"] and current_value > sla_metric.threshold_critical:
                severity = AlertSeverity.CRITICAL
            elif sla_metric.name in ["response_time_p95", "error_rate_percentage"] and current_value > sla_metric.threshold_warning:
                severity = AlertSeverity.HIGH
            else:
                # No violation - check if we need to resolve existing violation
                if violation_key in self.active_violations:
                    await self._resolve_sla_violation(violation_key)
                return

            # Create or update violation
            if violation_key not in self.active_violations:
                violation = SLAViolation(
                    id=violation_key,
                    metric_name=sla_metric.name,
                    service_name="platform",  # Or derive from metric
                    violation_type="threshold_breach",
                    severity=severity,
                    threshold_value=sla_metric.threshold_critical if severity == AlertSeverity.CRITICAL else sla_metric.threshold_warning,
                    actual_value=current_value,
                    started_at=datetime.utcnow(),
                    ended_at=None,
                    organization_id=sla_metric.organization_id or "default"
                )

                self.active_violations[violation_key] = violation

                # Record in database
                await self._record_sla_violation(violation)

                # Update Prometheus alert counter
                self.alert_counter.labels(
                    severity=severity.value,
                    service="platform",
                    organization=sla_metric.organization_id or "default"
                ).inc()

                logging.warning(
                    f"SLA violation detected: {sla_metric.name} = {current_value} "
                    f"(threshold: {violation.threshold_value})"
                )

        except Exception as e:
            logging.error(f"Error checking SLA violation: {e}")

    async def _record_sla_violation(self, violation: SLAViolation):
        """Record SLA violation in database."""
        try:
            async with self.postgres_pool.acquire() as conn:
                await conn.execute(
                    """
                    INSERT INTO sla_violations
                    (id, metric_name, service_name, violation_type, severity,
                     threshold_value, actual_value, started_at, organization_id)
                    VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)
                    """,
                    violation.id,
                    violation.metric_name,
                    violation.service_name,
                    violation.violation_type,
                    violation.severity.value,
                    violation.threshold_value,
                    violation.actual_value,
                    violation.started_at,
                    violation.organization_id
                )

        except Exception as e:
            logging.error(f"Error recording SLA violation: {e}")

    async def _resolve_sla_violation(self, violation_key: str):
        """Resolve an active SLA violation."""
        try:
            if violation_key in self.active_violations:
                violation = self.active_violations[violation_key]
                violation.ended_at = datetime.utcnow()

                # Update in database
                async with self.postgres_pool.acquire() as conn:
                    await conn.execute(
                        """
                        UPDATE sla_violations
                        SET ended_at = $1
                        WHERE id = $2
                        """,
                        violation.ended_at,
                        violation.id
                    )

                # Remove from active violations
                del self.active_violations[violation_key]

                logging.info(f"SLA violation resolved: {violation.metric_name}")

        except Exception as e:
            logging.error(f"Error resolving SLA violation: {e}")

    async def get_sla_compliance_report(
        self,
        organization_id: str,
        start_date: datetime,
        end_date: datetime
    ) -> Dict[str, Any]:
        """Generate SLA compliance report for organization."""
        try:
            async with self.postgres_pool.acquire() as conn:
                # Calculate uptime percentage
                total_checks = await conn.fetchval(
                    """
                    SELECT COUNT(*) FROM service_status_history
                    WHERE checked_at BETWEEN $1 AND $2
                    AND organization_id = $3
                    """,
                    start_date, end_date, organization_id
                )

                up_checks = await conn.fetchval(
                    """
                    SELECT COUNT(*) FROM service_status_history
                    WHERE checked_at BETWEEN $1 AND $2
                    AND status = 'up'
                    AND organization_id = $3
                    """,
                    start_date, end_date, organization_id
                )

                uptime_percentage = (up_checks / total_checks * 100) if total_checks > 0 else 0

                # Get violations
                violations = await conn.fetch(
                    """
                    SELECT * FROM sla_violations
                    WHERE organization_id = $1
                    AND started_at BETWEEN $2 AND $3
                    ORDER BY started_at DESC
                    """,
                    organization_id, start_date, end_date
                )

                # Calculate downtime duration
                downtime_minutes = await conn.fetchval(
                    """
                    SELECT COUNT(*) * 1.0 FROM service_status_history
                    WHERE checked_at BETWEEN $1 AND $2
                    AND status != 'up'
                    AND organization_id = $3
                    """,
                    start_date, end_date, organization_id
                ) or 0

                # Convert to actual minutes (assuming 1-minute check intervals)
                downtime_minutes = downtime_minutes * 1

                report = {
                    "organization_id": organization_id,
                    "report_period": {
                        "start": start_date.isoformat(),
                        "end": end_date.isoformat()
                    },
                    "sla_metrics": {
                        "uptime_percentage": round(uptime_percentage, 4),
                        "downtime_minutes": downtime_minutes,
                        "total_checks": total_checks,
                        "successful_checks": up_checks
                    },
                    "violations": [dict(violation) for violation in violations],
                    "compliance_summary": {
                        "sla_target": 99.9,
                        "achieved_uptime": round(uptime_percentage, 4),
                        "compliance_met": uptime_percentage >= 99.9,
                        "violation_count": len(violations)
                    },
                    "generated_at": datetime.utcnow().isoformat()
                }

                return report

        except Exception as e:
            logging.error(f"Error generating SLA compliance report: {e}")
            raise

    async def _cleanup_old_data(self):
        """Clean up old monitoring data."""
        while True:
            try:
                # Clean up data older than 90 days
                cutoff_date = datetime.utcnow() - timedelta(days=90)

                async with self.postgres_pool.acquire() as conn:
                    # Clean up old service status history
                    deleted_count = await conn.fetchval(
                        """
                        DELETE FROM service_status_history
                        WHERE checked_at < $1
                        RETURNING COUNT(*)
                        """,
                        cutoff_date
                    )

                    if deleted_count:
                        logging.info(f"Cleaned up {deleted_count} old service status records")

                # Sleep for 24 hours before next cleanup
                await asyncio.sleep(86400)

            except Exception as e:
                logging.error(f"Error in data cleanup: {e}")
                await asyncio.sleep(3600)  # Wait 1 hour on error
```

### 2. Alerting and Notification System (`app/sla_monitoring/alerting.py`):
```python
import asyncio
import json
import logging
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from enum import Enum
import aioredis
import asyncpg
import httpx
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

class NotificationChannel(Enum):
    """Notification channel types."""
    EMAIL = "email"
    SLACK = "slack"
    PAGERDUTY = "pagerduty"
    SMS = "sms"
    WEBHOOK = "webhook"

@dataclass
class NotificationRule:
    """Notification rule configuration."""
    id: str
    name: str
    organization_id: str
    severity_threshold: str  # minimum severity to trigger
    channels: List[NotificationChannel]
    recipients: List[str]
    escalation_delay_minutes: int
    is_active: bool = True

@dataclass
class EscalationPolicy:
    """Alert escalation policy."""
    id: str
    name: str
    organization_id: str
    levels: List[Dict[str, Any]]  # Each level has delay and recipients
    is_active: bool = True

class EnterpriseAlertingSystem:
    """Enterprise alerting and notification system."""

    def __init__(self, postgres_url: str, redis_url: str, config: Dict[str, Any]):
        self.postgres_url = postgres_url
        self.redis_url = redis_url
        self.config = config
        self.postgres_pool = None
        self.redis_pool = None

        # Notification configuration
        self.notification_rules: Dict[str, NotificationRule] = {}
        self.escalation_policies: Dict[str, EscalationPolicy] = {}
        self.active_alerts: Dict[str, Dict[str, Any]] = {}

        # Notification clients
        self.notification_clients = {}

    async def initialize(self):
        """Initialize alerting system."""
        try:
            # Initialize database connections
            self.postgres_pool = await asyncpg.create_pool(
                self.postgres_url,
                min_size=3,
                max_size=8
            )

            self.redis_pool = aioredis.ConnectionPool.from_url(
                self.redis_url, max_connections=8
            )

            # Create alerting tables
            await self._create_alerting_tables()

            # Load configuration
            await self._load_alerting_configuration()

            # Initialize notification clients
            await self._initialize_notification_clients()

            # Start background tasks
            asyncio.create_task(self._process_alert_queue())
            asyncio.create_task(self._handle_escalations())

            logging.info("Enterprise Alerting System initialized successfully")

        except Exception as e:
            logging.error(f"Failed to initialize alerting system: {e}")
            raise

    async def _create_alerting_tables(self):
        """Create alerting database tables."""
        try:
            async with self.postgres_pool.acquire() as conn:
                # Notification rules table
                await conn.execute("""
                    CREATE TABLE IF NOT EXISTS notification_rules (
                        id VARCHAR PRIMARY KEY,
                        name VARCHAR NOT NULL,
                        organization_id VARCHAR NOT NULL,
                        severity_threshold VARCHAR NOT NULL,
                        channels JSONB NOT NULL,
                        recipients JSONB NOT NULL,
                        escalation_delay_minutes INTEGER NOT NULL,
                        is_active BOOLEAN DEFAULT TRUE,
                        created_at TIMESTAMP DEFAULT NOW()
                    )
                """)

                # Escalation policies table
                await conn.execute("""
                    CREATE TABLE IF NOT EXISTS escalation_policies (
                        id VARCHAR PRIMARY KEY,
                        name VARCHAR NOT NULL,
                        organization_id VARCHAR NOT NULL,
                        levels JSONB NOT NULL,
                        is_active BOOLEAN DEFAULT TRUE,
                        created_at TIMESTAMP DEFAULT NOW()
                    )
                """)

                # Alert history table
                await conn.execute("""
                    CREATE TABLE IF NOT EXISTS alert_history (
                        id VARCHAR PRIMARY KEY,
                        alert_type VARCHAR NOT NULL,
                        severity VARCHAR NOT NULL,
                        service_name VARCHAR NOT NULL,
                        organization_id VARCHAR NOT NULL,
                        title VARCHAR NOT NULL,
                        description TEXT,
                        metadata JSONB,
                        triggered_at TIMESTAMP NOT NULL,
                        resolved_at TIMESTAMP,
                        acknowledged_at TIMESTAMP,
                        acknowledged_by VARCHAR
                    )
                """)

                # Notification history table
                await conn.execute("""
                    CREATE TABLE IF NOT EXISTS notification_history (
                        id VARCHAR PRIMARY KEY,
                        alert_id VARCHAR NOT NULL,
                        channel VARCHAR NOT NULL,
                        recipient VARCHAR NOT NULL,
                        sent_at TIMESTAMP NOT NULL,
                        delivery_status VARCHAR NOT NULL,
                        error_message TEXT,
                        organization_id VARCHAR NOT NULL
                    )
                """)

        except Exception as e:
            logging.error(f"Error creating alerting tables: {e}")
            raise

    async def _load_alerting_configuration(self):
        """Load alerting configuration from database."""
        try:
            async with self.postgres_pool.acquire() as conn:
                # Load notification rules
                rules = await conn.fetch(
                    "SELECT * FROM notification_rules WHERE is_active = TRUE"
                )

                for rule in rules:
                    notification_rule = NotificationRule(
                        id=rule["id"],
                        name=rule["name"],
                        organization_id=rule["organization_id"],
                        severity_threshold=rule["severity_threshold"],
                        channels=[NotificationChannel(ch) for ch in rule["channels"]],
                        recipients=rule["recipients"],
                        escalation_delay_minutes=rule["escalation_delay_minutes"],
                        is_active=rule["is_active"]
                    )
                    self.notification_rules[rule["id"]] = notification_rule

                # Load escalation policies
                policies = await conn.fetch(
                    "SELECT * FROM escalation_policies WHERE is_active = TRUE"
                )

                for policy in policies:
                    escalation_policy = EscalationPolicy(
                        id=policy["id"],
                        name=policy["name"],
                        organization_id=policy["organization_id"],
                        levels=policy["levels"],
                        is_active=policy["is_active"]
                    )
                    self.escalation_policies[policy["id"]] = escalation_policy

        except Exception as e:
            logging.error(f"Error loading alerting configuration: {e}")
            raise

    async def _initialize_notification_clients(self):
        """Initialize notification channel clients."""
        try:
            # Initialize email client
            if "smtp" in self.config:
                self.notification_clients[NotificationChannel.EMAIL] = {
                    "smtp_server": self.config["smtp"]["server"],
                    "smtp_port": self.config["smtp"]["port"],
                    "username": self.config["smtp"]["username"],
                    "password": self.config["smtp"]["password"],
                    "from_address": self.config["smtp"]["from_address"]
                }

            # Initialize Slack client
            if "slack" in self.config:
                self.notification_clients[NotificationChannel.SLACK] = {
                    "webhook_url": self.config["slack"]["webhook_url"],
                    "bot_token": self.config["slack"].get("bot_token")
                }

            # Initialize PagerDuty client
            if "pagerduty" in self.config:
                self.notification_clients[NotificationChannel.PAGERDUTY] = {
                    "integration_key": self.config["pagerduty"]["integration_key"],
                    "api_url": self.config["pagerduty"].get("api_url", "https://events.pagerduty.com/v2/enqueue")
                }

        except Exception as e:
            logging.error(f"Error initializing notification clients: {e}")
            raise

    async def send_alert(
        self,
        alert_type: str,
        severity: str,
        service_name: str,
        organization_id: str,
        title: str,
        description: str,
        metadata: Optional[Dict[str, Any]] = None
    ) -> str:
        """Send alert through configured notification channels."""
        try:
            alert_id = f"{alert_type}_{service_name}_{int(datetime.utcnow().timestamp())}"

            # Record alert in database
            async with self.postgres_pool.acquire() as conn:
                await conn.execute(
                    """
                    INSERT INTO alert_history
                    (id, alert_type, severity, service_name, organization_id,
                     title, description, metadata, triggered_at)
                    VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)
                    """,
                    alert_id, alert_type, severity, service_name, organization_id,
                    title, description, json.dumps(metadata or {}), datetime.utcnow()
                )

            # Find applicable notification rules
            applicable_rules = self._find_applicable_rules(severity, organization_id)

            # Queue notifications
            for rule in applicable_rules:
                await self._queue_notifications(alert_id, rule, {
                    "alert_type": alert_type,
                    "severity": severity,
                    "service_name": service_name,
                    "title": title,
                    "description": description,
                    "metadata": metadata or {}
                })

            # Store alert for escalation tracking
            self.active_alerts[alert_id] = {
                "severity": severity,
                "organization_id": organization_id,
                "triggered_at": datetime.utcnow(),
                "acknowledged": False,
                "resolved": False
            }

            return alert_id

        except Exception as e:
            logging.error(f"Error sending alert: {e}")
            raise

    def _find_applicable_rules(self, severity: str, organization_id: str) -> List[NotificationRule]:
        """Find notification rules applicable to the alert."""
        applicable_rules = []
        severity_order = ["info", "low", "medium", "high", "critical"]

        for rule in self.notification_rules.values():
            if (rule.organization_id == organization_id and
                rule.is_active and
                severity_order.index(severity) >= severity_order.index(rule.severity_threshold)):
                applicable_rules.append(rule)

        return applicable_rules

    async def _queue_notifications(self, alert_id: str, rule: NotificationRule, alert_data: Dict[str, Any]):
        """Queue notifications for immediate delivery."""
        try:
            redis = aioredis.Redis(connection_pool=self.redis_pool)

            for channel in rule.channels:
                for recipient in rule.recipients:
                    notification = {
                        "alert_id": alert_id,
                        "channel": channel.value,
                        "recipient": recipient,
                        "alert_data": alert_data,
                        "rule_id": rule.id,
                        "scheduled_at": datetime.utcnow().isoformat()
                    }

                    await redis.lpush(
                        "alert_notifications",
                        json.dumps(notification, default=str)
                    )

        except Exception as e:
            logging.error(f"Error queueing notifications: {e}")

    async def _process_alert_queue(self):
        """Process queued alert notifications."""
        while True:
            try:
                redis = aioredis.Redis(connection_pool=self.redis_pool)

                # Get notification from queue
                notification_data = await redis.brpop("alert_notifications", timeout=30)

                if notification_data:
                    notification = json.loads(notification_data[1])
                    await self._deliver_notification(notification)

            except Exception as e:
                logging.error(f"Error processing alert queue: {e}")
                await asyncio.sleep(10)

    async def _deliver_notification(self, notification: Dict[str, Any]):
        """Deliver individual notification."""
        try:
            channel = NotificationChannel(notification["channel"])
            recipient = notification["recipient"]
            alert_data = notification["alert_data"]

            delivery_status = "failed"
            error_message = None

            try:
                if channel == NotificationChannel.EMAIL:
                    await self._send_email_notification(recipient, alert_data)
                    delivery_status = "delivered"

                elif channel == NotificationChannel.SLACK:
                    await self._send_slack_notification(recipient, alert_data)
                    delivery_status = "delivered"

                elif channel == NotificationChannel.PAGERDUTY:
                    await self._send_pagerduty_notification(recipient, alert_data)
                    delivery_status = "delivered"

            except Exception as e:
                error_message = str(e)
                logging.error(f"Failed to deliver {channel.value} notification: {e}")

            # Record delivery status
            await self._record_notification_delivery(
                notification["alert_id"],
                channel.value,
                recipient,
                delivery_status,
                error_message,
                alert_data.get("organization_id", "unknown")
            )

        except Exception as e:
            logging.error(f"Error delivering notification: {e}")

    async def _send_email_notification(self, recipient: str, alert_data: Dict[str, Any]):
        """Send email notification."""
        try:
            email_config = self.notification_clients[NotificationChannel.EMAIL]

            # Create email message
            msg = MIMEMultipart()
            msg['From'] = email_config["from_address"]
            msg['To'] = recipient
            msg['Subject'] = f"SLA Alert: {alert_data['title']}"

            # Create email body
            body = f"""
SLA Alert Notification

Service: {alert_data['service_name']}
Severity: {alert_data['severity'].upper()}
Alert Type: {alert_data['alert_type']}

{alert_data['title']}

Description:
{alert_data['description']}

Time: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')}

Please investigate and take appropriate action.
            """

            msg.attach(MIMEText(body, 'plain'))

            # Send email (in production, use async email sending)
            # This is a simplified synchronous version
            server = smtplib.SMTP(email_config["smtp_server"], email_config["smtp_port"])
            server.starttls()
            server.login(email_config["username"], email_config["password"])
            server.send_message(msg)
            server.quit()

        except Exception as e:
            logging.error(f"Error sending email notification: {e}")
            raise

    async def _send_slack_notification(self, recipient: str, alert_data: Dict[str, Any]):
        """Send Slack notification."""
        try:
            slack_config = self.notification_clients[NotificationChannel.SLACK]

            # Create Slack message
            message = {
                "text": f"SLA Alert: {alert_data['title']}",
                "channel": recipient,
                "attachments": [
                    {
                        "color": self._get_alert_color(alert_data['severity']),
                        "fields": [
                            {
                                "title": "Service",
                                "value": alert_data['service_name'],
                                "short": True
                            },
                            {
                                "title": "Severity",
                                "value": alert_data['severity'].upper(),
                                "short": True
                            },
                            {
                                "title": "Description",
                                "value": alert_data['description'],
                                "short": False
                            }
                        ],
                        "ts": int(datetime.utcnow().timestamp())
                    }
                ]
            }

            # Send to Slack
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    slack_config["webhook_url"],
                    json=message
                )
                response.raise_for_status()

        except Exception as e:
            logging.error(f"Error sending Slack notification: {e}")
            raise

    def _get_alert_color(self, severity: str) -> str:
        """Get color for alert based on severity."""
        color_map = {
            "critical": "danger",
            "high": "warning",
            "medium": "warning",
            "low": "good",
            "info": "good"
        }
        return color_map.get(severity, "warning")

    async def _record_notification_delivery(
        self,
        alert_id: str,
        channel: str,
        recipient: str,
        delivery_status: str,
        error_message: Optional[str],
        organization_id: str
    ):
        """Record notification delivery status."""
        try:
            async with self.postgres_pool.acquire() as conn:
                await conn.execute(
                    """
                    INSERT INTO notification_history
                    (id, alert_id, channel, recipient, sent_at, delivery_status,
                     error_message, organization_id)
                    VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
                    """,
                    f"{alert_id}_{channel}_{recipient}_{int(datetime.utcnow().timestamp())}",
                    alert_id,
                    channel,
                    recipient,
                    datetime.utcnow(),
                    delivery_status,
                    error_message,
                    organization_id
                )

        except Exception as e:
            logging.error(f"Error recording notification delivery: {e}")
```

## Dependencies
- asyncpg for high-performance PostgreSQL operations
- aioredis for caching and queue management
- prometheus_client for metrics exposition
- httpx for HTTP client operations
- smtplib for email notifications
- asyncio for concurrent processing

## Acceptance Criteria
- [ ] SLA monitoring achieves 99.9% uptime measurement accuracy with <5 second detection
- [ ] Automated alerting delivers notifications within 30 seconds of threshold breach
- [ ] Enterprise dashboard updates in real-time with 5-second refresh intervals
- [ ] Compliance reporting generates accurate monthly reports with 100% data integrity
- [ ] Multi-channel alerting supports email, Slack, PagerDuty, and webhooks
- [ ] Escalation policies execute automatically with configurable delays and recipients

## Time Estimate
**Total: 22-28 days**
- SLA monitoring core implementation: 8-10 days
- Alerting and notification system: 6-8 days
- Reporting and dashboard integration: 4-5 days
- Enterprise integration features: 3-4 days
- Testing and optimization: 2-3 days

## Required Skills
- Advanced monitoring and observability patterns
- Prometheus metrics and alerting experience
- Multi-channel notification systems
- Enterprise SLA and compliance requirements
- Real-time data processing and aggregation
- Incident management and escalation workflows

## Risks
- **High**: Alert fatigue from overly sensitive thresholds
- **Medium**: Notification delivery reliability across channels
- **Medium**: Performance impact of continuous monitoring
- **Low**: SLA calculation accuracy edge cases

## Additional Notes
- Implement comprehensive monitoring for the monitoring system itself
- Use circuit breakers for external notification services
- Ensure GDPR compliance for monitoring data retention
- Consider implementing smart alerting to reduce noise and improve signal-to-noise ratio
